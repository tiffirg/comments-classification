{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import seaborn as sns\n",
    "from typing import Any\n",
    "from functools import partial\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation as PUNCT\n",
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    multilabel_confusion_matrix,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Направление</th><th>Факультет</th><th>ID студента</th><th>Оценка</th><th>Категория</th><th>Тег</th><th>Комментарий</th><th>Статус</th><th>Neutral</th><th>Positive</th><th>Negative</th><th>Exclamations</th><th>have_code</th><th>Neutral_NLP</th><th>Positive_NLP</th><th>Negative_NLP</th><th>Speech_NLP</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;C&quot;</td><td>113.0</td><td>1493.0</td><td>1.0</td><td>&quot;Видео&quot;</td><td>&quot;VP2&quot;</td><td>&quot;Видео лагает&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>1.00001</td><td>0.010663</td><td>0.00001</td><td>0.00001</td></tr><tr><td>&quot;C&quot;</td><td>113.0</td><td>5580.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Торгом Бабаян!…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5</td><td>false</td><td>0.437833</td><td>0.056662</td><td>0.140346</td><td>0.051855</td></tr><tr><td>&quot;E&quot;</td><td>126.0</td><td>5619.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3&quot;</td><td>&quot;Спасибо)&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.00001</td><td>0.00001</td><td>0.00001</td><td>1.00001</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>310.0</td><td>3.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H2 E1&quot;</td><td>&quot;комментарий со…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.930468</td><td>0.025189</td><td>0.119213</td><td>0.000378</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>1913.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Жонибек, хочу …</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2</td><td>false</td><td>0.069552</td><td>0.217348</td><td>0.019134</td><td>0.507822</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 17)\n",
       "┌────────────┬───────────┬────────────┬────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Направлени ┆ Факультет ┆ ID         ┆ Оценка ┆ … ┆ Neutral_N ┆ Positive_ ┆ Negative_ ┆ Speech_NL │\n",
       "│ е          ┆ ---       ┆ студента   ┆ ---    ┆   ┆ LP        ┆ NLP       ┆ NLP       ┆ P         │\n",
       "│ ---        ┆ f64       ┆ ---        ┆ f64    ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ str        ┆           ┆ f64        ┆        ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪════════════╪════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ C          ┆ 113.0     ┆ 1493.0     ┆ 1.0    ┆ … ┆ 1.00001   ┆ 0.010663  ┆ 0.00001   ┆ 0.00001   │\n",
       "│ C          ┆ 113.0     ┆ 5580.0     ┆ 5.0    ┆ … ┆ 0.437833  ┆ 0.056662  ┆ 0.140346  ┆ 0.051855  │\n",
       "│ E          ┆ 126.0     ┆ 5619.0     ┆ 5.0    ┆ … ┆ 0.00001   ┆ 0.00001   ┆ 0.00001   ┆ 1.00001   │\n",
       "│ E          ┆ 123.0     ┆ 310.0      ┆ 3.0    ┆ … ┆ 0.930468  ┆ 0.025189  ┆ 0.119213  ┆ 0.000378  │\n",
       "│ E          ┆ 123.0     ┆ 1913.0     ┆ 5.0    ┆ … ┆ 0.069552  ┆ 0.217348  ┆ 0.019134  ┆ 0.507822  │\n",
       "└────────────┴───────────┴────────────┴────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pl.read_csv(\"preprocessing.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_258, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Тег</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;VC2 VC4 VP1&quot;</td><td>1</td></tr><tr><td>&quot;S1 H3 VC3 S3&quot;</td><td>1</td></tr><tr><td>&quot;VC3 VP3 H3 LMS…</td><td>1</td></tr><tr><td>&quot;H1 E1 D&quot;</td><td>1</td></tr><tr><td>&quot;H3 VC3 VP2 VC2…</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;H2 H3 VC1&quot;</td><td>1</td></tr><tr><td>&quot;VC2 VP3 S3&quot;</td><td>1</td></tr><tr><td>&quot;VC2 H2 &quot;</td><td>14</td></tr><tr><td>&quot;VC3 VP3 H3 VC1…</td><td>1</td></tr><tr><td>&quot;VP3 H1 H3&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_258, 2)\n",
       "┌────────────────────┬───────┐\n",
       "│ Тег                ┆ count │\n",
       "│ ---                ┆ ---   │\n",
       "│ str                ┆ u32   │\n",
       "╞════════════════════╪═══════╡\n",
       "│ VC2 VC4 VP1        ┆ 1     │\n",
       "│ S1 H3 VC3 S3       ┆ 1     │\n",
       "│ VC3 VP3 H3 LMS S4  ┆ 1     │\n",
       "│ H1 E1 D            ┆ 1     │\n",
       "│ H3 VC3 VP2 VC2     ┆ 1     │\n",
       "│ …                  ┆ …     │\n",
       "│ H2 H3 VC1          ┆ 1     │\n",
       "│ VC2 VP3 S3         ┆ 1     │\n",
       "│ VC2 H2             ┆ 14    │\n",
       "│ VC3 VP3 H3 VC1 S1  ┆ 1     │\n",
       "│ VP3 H1 H3          ┆ 1     │\n",
       "└────────────────────┴───────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Тег\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_columns(\n",
    "    (pl.col(\"Тег\").apply(lambda x: \" \".join(re.findall(r\"[A-Z]{1,2}\\d|LMS\", x)))).alias(\"corrected_tag\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_filter = (\n",
    "    (pl.col(\"corrected_tag\").eq(\"\"))\n",
    ")\n",
    "\n",
    "dataset = dataset.filter(~null_filter)\n",
    "dataset = dataset.filter(~(pl.col(\"Комментарий\").is_null()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_columns(\n",
    "    pl.col(\"corrected_tag\")\n",
    "    .str.replace_all(r\"VC4|VP4|VC5|S4|T4|H4|EA1\", \"\")\n",
    "    .str.strip()\n",
    "    .str.replace(r\"\\s\\s+\", \" \")\n",
    "    .str.replace(r\"GH3\", \"H3\")\n",
    "    .str.replace(r\"HH3\", \"H3\")\n",
    "    .str.replace(r\"BP3\", \"VP3\")\n",
    "    .str.replace(r\"V3\", \"VC3\")\n",
    "    .str.replace(r\"V2\", \"VP2\")\n",
    ")\n",
    "\n",
    "dataset = dataset.filter(~(pl.col(\"corrected_tag\").eq(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (17, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>corrected_tag</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;H3&quot;</td><td>20391</td></tr><tr><td>&quot;VC2&quot;</td><td>14414</td></tr><tr><td>&quot;VC3&quot;</td><td>8111</td></tr><tr><td>&quot;VP3&quot;</td><td>4972</td></tr><tr><td>&quot;VP2&quot;</td><td>4897</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;LMS&quot;</td><td>669</td></tr><tr><td>&quot;T2&quot;</td><td>548</td></tr><tr><td>&quot;T1&quot;</td><td>399</td></tr><tr><td>&quot;T3&quot;</td><td>234</td></tr><tr><td>&quot;E2&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (17, 2)\n",
       "┌───────────────┬───────┐\n",
       "│ corrected_tag ┆ count │\n",
       "│ ---           ┆ ---   │\n",
       "│ str           ┆ u32   │\n",
       "╞═══════════════╪═══════╡\n",
       "│ H3            ┆ 20391 │\n",
       "│ VC2           ┆ 14414 │\n",
       "│ VC3           ┆ 8111  │\n",
       "│ VP3           ┆ 4972  │\n",
       "│ VP2           ┆ 4897  │\n",
       "│ …             ┆ …     │\n",
       "│ LMS           ┆ 669   │\n",
       "│ T2            ┆ 548   │\n",
       "│ T1            ┆ 399   │\n",
       "│ T3            ┆ 234   │\n",
       "│ E2            ┆ 1     │\n",
       "└───────────────┴───────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"corrected_tag\"].str.split(by = \" \").explode().value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(~pl.col(\"corrected_tag\").str.contains(\"E2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>corrected_tag</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;VC&quot;</td><td>26304</td></tr><tr><td>&quot;H&quot;</td><td>24437</td></tr><tr><td>&quot;VP&quot;</td><td>11560</td></tr><tr><td>&quot;S&quot;</td><td>1973</td></tr><tr><td>&quot;E&quot;</td><td>1785</td></tr><tr><td>&quot;T&quot;</td><td>1181</td></tr><tr><td>&quot;LMS&quot;</td><td>669</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌───────────────┬───────┐\n",
       "│ corrected_tag ┆ count │\n",
       "│ ---           ┆ ---   │\n",
       "│ str           ┆ u32   │\n",
       "╞═══════════════╪═══════╡\n",
       "│ VC            ┆ 26304 │\n",
       "│ H             ┆ 24437 │\n",
       "│ VP            ┆ 11560 │\n",
       "│ S             ┆ 1973  │\n",
       "│ E             ┆ 1785  │\n",
       "│ T             ┆ 1181  │\n",
       "│ LMS           ┆ 669   │\n",
       "└───────────────┴───────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_sub_tags(tags: str):\n",
    "    split = tags.split(sep=\" \")\n",
    "    new_tag = [x[:-1] if x[-1].isdigit() else x for x in split]\n",
    "    return \" \".join(new_tag)\n",
    "\n",
    "dataset = dataset.with_columns(\n",
    "    pl.col(\"corrected_tag\").apply(remove_sub_tags)\n",
    ")\n",
    "\n",
    "dataset[\"corrected_tag\"].str.split(by = \" \").explode().value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset[\"corrected_tag\"].str.split(by = \" \").explode().unique().sort().to_list()\n",
    "target = dict(zip(target, range(len(target))))\n",
    "reverse_target = {v : k for k, v in target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tags: str) -> list[float]:\n",
    "    \"\"\"Turn str with tags into list with digit labels.\n",
    "\n",
    "    Args:\n",
    "        tags (str): tag text representation.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: numeric labels.\n",
    "    \"\"\"\n",
    "    split = tags.split(sep = \" \")\n",
    "    res = np.zeros(len(target))\n",
    "    for x in split:\n",
    "        res[target[x]] = 1\n",
    "    return res.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_columns(pl.col(\"corrected_tag\").apply(vectorize).alias(\"labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (54_648, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Направление</th><th>Факультет</th><th>ID студента</th><th>Оценка</th><th>Категория</th><th>Тег</th><th>Комментарий</th><th>Статус</th><th>Neutral</th><th>Positive</th><th>Negative</th><th>Exclamations</th><th>have_code</th><th>Neutral_NLP</th><th>Positive_NLP</th><th>Negative_NLP</th><th>Speech_NLP</th><th>corrected_tag</th><th>labels</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>list[f64]</td></tr></thead><tbody><tr><td>&quot;C&quot;</td><td>113.0</td><td>1493.0</td><td>1.0</td><td>&quot;Видео&quot;</td><td>&quot;VP2&quot;</td><td>&quot;Видео лагает&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>1.00001</td><td>0.010663</td><td>0.00001</td><td>0.00001</td><td>&quot;VP&quot;</td><td>[0.0, 0.0, … 1.0]</td></tr><tr><td>&quot;C&quot;</td><td>113.0</td><td>5580.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Торгом Бабаян!…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5</td><td>false</td><td>0.437833</td><td>0.056662</td><td>0.140346</td><td>0.051855</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&quot;E&quot;</td><td>126.0</td><td>5619.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3&quot;</td><td>&quot;Спасибо)&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.00001</td><td>0.00001</td><td>0.00001</td><td>1.00001</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>310.0</td><td>3.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H2 E1&quot;</td><td>&quot;комментарий со…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.930468</td><td>0.025189</td><td>0.119213</td><td>0.000378</td><td>&quot;H E&quot;</td><td>[1.0, 1.0, … 0.0]</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>1913.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Жонибек, хочу …</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2</td><td>false</td><td>0.069552</td><td>0.217348</td><td>0.019134</td><td>0.507822</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Z&quot;</td><td>133.0</td><td>null</td><td>3.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H2&quot;</td><td>&quot;требуемый форм…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.822199</td><td>0.013647</td><td>0.020974</td><td>0.00001</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>&quot;S1&quot;</td><td>&quot;заплатила и да…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.228166</td><td>0.042098</td><td>0.644235</td><td>0.006108</td><td>&quot;S&quot;</td><td>[0.0, 0.0, … 0.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>7.0</td><td>null</td><td>&quot;LMS&quot;</td><td>&quot;Крайне раздраж…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.692652</td><td>0.073706</td><td>0.262852</td><td>0.00523</td><td>&quot;LMS&quot;</td><td>[0.0, 0.0, … 0.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;VC2 VP2&quot;</td><td>&quot;Аналитик данны…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>true</td><td>0.705795</td><td>0.053413</td><td>0.320831</td><td>0.001511</td><td>&quot;VC VP&quot;</td><td>[0.0, 0.0, … 1.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;VP2 VC2&quot;</td><td>&quot;Системный анал…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.679189</td><td>0.092698</td><td>0.156115</td><td>0.00408</td><td>&quot;VP VC&quot;</td><td>[0.0, 0.0, … 1.0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (54_648, 19)\n",
       "┌────────────┬───────────┬────────────┬────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Направлени ┆ Факультет ┆ ID         ┆ Оценка ┆ … ┆ Negative_ ┆ Speech_NL ┆ corrected ┆ labels    │\n",
       "│ е          ┆ ---       ┆ студента   ┆ ---    ┆   ┆ NLP       ┆ P         ┆ _tag      ┆ ---       │\n",
       "│ ---        ┆ f64       ┆ ---        ┆ f64    ┆   ┆ ---       ┆ ---       ┆ ---       ┆ list[f64] │\n",
       "│ str        ┆           ┆ f64        ┆        ┆   ┆ f64       ┆ f64       ┆ str       ┆           │\n",
       "╞════════════╪═══════════╪════════════╪════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ C          ┆ 113.0     ┆ 1493.0     ┆ 1.0    ┆ … ┆ 0.00001   ┆ 0.00001   ┆ VP        ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0]      │\n",
       "│ C          ┆ 113.0     ┆ 5580.0     ┆ 5.0    ┆ … ┆ 0.140346  ┆ 0.051855  ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ E          ┆ 126.0     ┆ 5619.0     ┆ 5.0    ┆ … ┆ 0.00001   ┆ 1.00001   ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ E          ┆ 123.0     ┆ 310.0      ┆ 3.0    ┆ … ┆ 0.119213  ┆ 0.000378  ┆ H E       ┆ [1.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ E          ┆ 123.0     ┆ 1913.0     ┆ 5.0    ┆ … ┆ 0.019134  ┆ 0.507822  ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ …          ┆ …         ┆ …          ┆ …      ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ Z          ┆ 133.0     ┆ null       ┆ 3.0    ┆ … ┆ 0.020974  ┆ 0.00001   ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ 0.0    ┆ … ┆ 0.644235  ┆ 0.006108  ┆ S         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ 7.0    ┆ … ┆ 0.262852  ┆ 0.00523   ┆ LMS       ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ null   ┆ … ┆ 0.320831  ┆ 0.001511  ┆ VC VP     ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ null   ┆ … ┆ 0.156115  ┆ 0.00408   ┆ VP VC     ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0]      │\n",
       "└────────────┴───────────┴────────────┴────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_dataset = dataset.select(\n",
    "    pl.col(\"Комментарий\"),\n",
    "    pl.col(\"Направление\"),\n",
    "    pl.col(\"Факультет\"),\n",
    "    pl.col(\"Оценка\"),\n",
    "    pl.col(\"Neutral\"),\n",
    "    pl.col(\"Positive\"),\n",
    "    pl.col(\"Negative\"),\n",
    "    pl.col(\"Exclamations\"),\n",
    "    pl.col(\"have_code\"),\n",
    "    pl.col(\"Neutral_NLP\"),\n",
    "    pl.col(\"Positive_NLP\"),\n",
    "    pl.col(\"Negative_NLP\"),\n",
    "    pl.col(\"Speech_NLP\"),\n",
    "    pl.col(\"corrected_tag\"),\n",
    "    pl.col(\"labels\"),\n",
    "    pl.col(\"corrected_tag\").str.split(by=\" \").alias(\"temp\"),\n",
    ")\n",
    "clear_dataset = clear_dataset.explode(columns=[\"temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    clear_dataset,\n",
    "    test_size=0.1,\n",
    "    random_state=3317,\n",
    "    stratify=clear_dataset[\"temp\"],\n",
    ")\n",
    "\n",
    "train_df = train_df.drop(columns=[\"corrected_tag\", \"temp\"])\n",
    "test_df = test_df.drop(columns=[\"corrected_tag\", \"temp\"])\n",
    "\n",
    "train_df = train_df.rename({\"Комментарий\": \"text\"})\n",
    "test_df = test_df.rename({\"Комментарий\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df.to_pandas(), split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_df.to_pandas(), split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "\n",
    "\n",
    "def preprocess_data(sample: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"Encode input text into sequence of tokens.\n",
    "    Also add corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        sample (dict[str, Any]): raw input text.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: transformed sample with tokenized text and labels.\n",
    "    \"\"\"\n",
    "    text = sample[\"text\"]\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    encoding[\"labels\"] = sample[\"labels\"]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bae7a4baf11465691dd8a00579ea467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61118 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d79bbc61504c819eb3429aa2b5cf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6791 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train = train_dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=train_dataset.column_names\n",
    ")\n",
    "encoded_test = test_dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=test_dataset.column_names\n",
    ")\n",
    "encoded_train.set_format(\"torch\")\n",
    "encoded_test.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(\n",
    "    predictions: np.ndarray, labels: np.ndarray, threshold: float = 0.5\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Compute mltilabel metrics.\n",
    "\n",
    "    Args:\n",
    "        predictions (np.ndarray): logits array\n",
    "        labels (np.ndarray): labels array\n",
    "        threshold (float, optional): activation threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: metrics dict\n",
    "    \"\"\"\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    f1_micro_average = f1_score(y_true=labels, y_pred=y_pred, average=\"micro\")\n",
    "    roc_auc = roc_auc_score(labels, y_pred, average=\"micro\")\n",
    "    accuracy = accuracy_score(labels, y_pred)\n",
    "    metrics = {\"f1\": f1_micro_average, \"roc_auc\": roc_auc, \"accuracy\": accuracy}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction) -> dict[str, float]:\n",
    "    \"\"\"Metrics computation wrapper.\n",
    "\n",
    "    Args:\n",
    "        p (EvalPrediction): hf model output\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: metrics dict\n",
    "    \"\"\"\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(predictions=preds, labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_pipeline(\n",
    "    exp_name: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    train_dataset: Dataset,\n",
    "    eval_dataset: Dataset,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 2e-5,\n",
    "    epochs_num: int = 20,\n",
    "    model_name=None\n",
    ") -> Trainer:\n",
    "    \"\"\"Training process wrapper.\n",
    "\n",
    "    Args:\n",
    "        exp_name (str): name of the local folder\n",
    "        for saving model checkpoints.\n",
    "        tokenizer (AutoTokenizer): model tokenizer\n",
    "        train_dataset (Dataset): train dataset split\n",
    "        eval_dataset (Dataset): test dataset split\n",
    "        batch_size (int, optional): number of samples\n",
    "        in sigle batch. Defaults to 32.\n",
    "        lr (float, optional): model's learning rate. Defaults to 2e-5.\n",
    "        epochs_num (int, optional):\n",
    "        number of training iterations. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        Trainer: hf training pipeline abstraction class.\n",
    "    \"\"\"\n",
    "    args = TrainingArguments(\n",
    "        exp_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs_num,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"cointegrated/rubert-tiny2\",\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(target),\n",
    "        id2label=target,\n",
    "        label2id=reverse_target\n",
    "    )\n",
    "    if model_name is not None:\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200\n",
    "EPOCHS = 30\n",
    "LR = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = make_training_pipeline(\"f\", tokenizer, encoded_train, encoded_test, batch_size=BATCH_SIZE, epochs_num=EPOCHS, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4590' max='4590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4590/4590 46:43, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.362707</td>\n",
       "      <td>0.611378</td>\n",
       "      <td>0.735777</td>\n",
       "      <td>0.434104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.282130</td>\n",
       "      <td>0.738106</td>\n",
       "      <td>0.821887</td>\n",
       "      <td>0.549109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246259</td>\n",
       "      <td>0.772854</td>\n",
       "      <td>0.847953</td>\n",
       "      <td>0.575909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.225135</td>\n",
       "      <td>0.792625</td>\n",
       "      <td>0.861576</td>\n",
       "      <td>0.603004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.211316</td>\n",
       "      <td>0.801652</td>\n",
       "      <td>0.866593</td>\n",
       "      <td>0.618760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>0.202338</td>\n",
       "      <td>0.808046</td>\n",
       "      <td>0.868281</td>\n",
       "      <td>0.630540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>0.196211</td>\n",
       "      <td>0.813972</td>\n",
       "      <td>0.873641</td>\n",
       "      <td>0.638492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>0.191724</td>\n",
       "      <td>0.817414</td>\n",
       "      <td>0.876922</td>\n",
       "      <td>0.643499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>0.187903</td>\n",
       "      <td>0.821382</td>\n",
       "      <td>0.880035</td>\n",
       "      <td>0.648800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.184308</td>\n",
       "      <td>0.824102</td>\n",
       "      <td>0.881242</td>\n",
       "      <td>0.651598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.181889</td>\n",
       "      <td>0.828181</td>\n",
       "      <td>0.884394</td>\n",
       "      <td>0.658224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.179332</td>\n",
       "      <td>0.832013</td>\n",
       "      <td>0.888732</td>\n",
       "      <td>0.665440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.177013</td>\n",
       "      <td>0.832994</td>\n",
       "      <td>0.888852</td>\n",
       "      <td>0.666618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.175346</td>\n",
       "      <td>0.835285</td>\n",
       "      <td>0.888677</td>\n",
       "      <td>0.674717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.173256</td>\n",
       "      <td>0.836442</td>\n",
       "      <td>0.889592</td>\n",
       "      <td>0.676042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.171421</td>\n",
       "      <td>0.839450</td>\n",
       "      <td>0.891491</td>\n",
       "      <td>0.680312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.170036</td>\n",
       "      <td>0.840372</td>\n",
       "      <td>0.892510</td>\n",
       "      <td>0.681490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.169391</td>\n",
       "      <td>0.842411</td>\n",
       "      <td>0.893923</td>\n",
       "      <td>0.686202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.168287</td>\n",
       "      <td>0.843482</td>\n",
       "      <td>0.894200</td>\n",
       "      <td>0.689000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.845696</td>\n",
       "      <td>0.896592</td>\n",
       "      <td>0.691209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.167057</td>\n",
       "      <td>0.847135</td>\n",
       "      <td>0.898694</td>\n",
       "      <td>0.695038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.166316</td>\n",
       "      <td>0.848261</td>\n",
       "      <td>0.899297</td>\n",
       "      <td>0.696657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.165550</td>\n",
       "      <td>0.849677</td>\n",
       "      <td>0.900018</td>\n",
       "      <td>0.699161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.164643</td>\n",
       "      <td>0.849987</td>\n",
       "      <td>0.900384</td>\n",
       "      <td>0.700633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.164723</td>\n",
       "      <td>0.850921</td>\n",
       "      <td>0.901794</td>\n",
       "      <td>0.701369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.164079</td>\n",
       "      <td>0.850812</td>\n",
       "      <td>0.900934</td>\n",
       "      <td>0.704020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.163983</td>\n",
       "      <td>0.851572</td>\n",
       "      <td>0.902018</td>\n",
       "      <td>0.705198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.164012</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.901860</td>\n",
       "      <td>0.705198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.163967</td>\n",
       "      <td>0.851343</td>\n",
       "      <td>0.901847</td>\n",
       "      <td>0.705051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.163815</td>\n",
       "      <td>0.852239</td>\n",
       "      <td>0.902280</td>\n",
       "      <td>0.706082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4590, training_loss=0.171588312618613, metrics={'train_runtime': 2804.8365, 'train_samples_per_second': 653.707, 'train_steps_per_second': 1.636, 'total_flos': 1.352971853236224e+16, 'train_loss': 0.171588312618613, 'epoch': 30.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1638152003288269,\n",
       " 'eval_f1': 0.8522388059701492,\n",
       " 'eval_roc_auc': 0.902280194811021,\n",
       " 'eval_accuracy': 0.7060815785598586,\n",
       " 'eval_runtime': 4.3008,\n",
       " 'eval_samples_per_second': 1579.005,\n",
       " 'eval_steps_per_second': 3.953,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = trainer.predict(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8522388059701492, 'roc_auc': 0.902280194811021, 'accuracy': 0.7060815785598586}\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = multilabel_confusion_matrix((test_preds.predictions > 0.5), test_preds.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[i for i in range(7)])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = make_training_pipeline(\"v\", tokenizer, encoded_train, encoded_test, batch_size=BATCH_SIZE, epochs_num=EPOCHS, lr=LR, model_name=\"f/checkpoint-4590/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_preds = trainer.predict(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделать сравнение с Focal Loss и без него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'Направление', 'Факультет', 'Оценка', 'Neutral', 'Positive', 'Negative', 'Exclamations', 'have_code', 'Neutral_NLP', 'Positive_NLP', 'Negative_NLP', 'Speech_NLP', 'labels'],\n",
       "    num_rows: 61118\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = pd.get_dummies(train_df.to_pandas()[\"Направление\"])\n",
    "departments = pd.get_dummies(train_df.to_pandas()[\"Факультет\"])\n",
    "meta_dataset_train = train_df.select(pl.exclude(\"Направление\", \"Факультет\")).to_pandas()\n",
    "meta_dataset_train = pd.concat([meta_dataset_train, directions, departments, pd.DataFrame(train_preds.predictions)], axis=1)\n",
    "meta_dataset_train = meta_dataset_train.drop(columns=[\"text\"])\n",
    "\n",
    "meta_dataset_test = test_df.select(pl.exclude(\"Направление\", \"Факультет\")).to_pandas()\n",
    "meta_dataset_test = pd.concat([meta_dataset_test, directions, departments, pd.DataFrame(test_preds.predictions)], axis=1)\n",
    "meta_dataset_test = meta_dataset_test.drop(columns=[\"text\"])\n",
    "\n",
    "meta_dataset_test = meta_dataset_test.dropna(subset=[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_train[[f\"label{i}\" for i in range(7)]] = np.array([el for el in meta_dataset_train[\"labels\"].to_numpy()])\n",
    "meta_dataset_test[[f\"label{i}\" for i in range(7)]] = np.array([el for el in meta_dataset_test[\"labels\"].to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_train = meta_dataset_train.drop(columns=[\"labels\"])\n",
    "meta_dataset_test = meta_dataset_test.drop(columns=[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"agModels-predictClass\"\n",
    "labels = [f\"label{i}\" for i in range(7)]\n",
    "problem_types = [f\"binary\" for i in range(7)]\n",
    "eval_metrics = [f\"roc_auc\" for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictClassPredictor_label0\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: agModels-predictClassPredictor_label0/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: label0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 948 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2652 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2652s\n",
      "AutoGluon will save models to \"agModels-predictClassPredictor_label0\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #112-Ubuntu SMP Tue Mar 5 16:50:32 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       97.84 GB / 125.73 GB (77.8%)\n",
      "Disk Space Avail:   28.12 GB / 97.87 GB (28.7%)\n",
      "===================================================\n",
      "Train Data Rows:    61118\n",
      "Train Data Columns: 82\n",
      "Label Column:       label0\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    100195.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.68 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 66 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 23): ['D', 'H', 'M', 'Q', 'S', 'T', 'U', 'V', 'W', 'X', '100.0', '109.0', '111.0', '112.0', '113.0', '115.0', '117.0', '118.0', '125.0', '126.0', '127.0', '129.0', '132.0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('bool', []) : 23 | ['D', 'H', 'M', 'Q', 'S', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 43 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t\t('float', []) : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])   :  1 | ['Exclamations']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])       :  1 | ['Exclamations']\n",
      "\t\t('int', ['bool']) : 43 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t59 features in original data used to generate 59 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.34 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1767.1s of the 2651.31s of remaining time.\n",
      "\t0.9517\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1766.49s of the 2650.7s of remaining time.\n",
      "\t0.9646\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1765.87s of the 2650.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9855\t = Validation score   (roc_auc)\n",
      "\t18.61s\t = Training   runtime\n",
      "\t1.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1745.68s of the 2629.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9867\t = Validation score   (roc_auc)\n",
      "\t8.54s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1735.74s of the 2619.95s of remaining time.\n",
      "\t0.9899\t = Validation score   (roc_auc)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1733.23s of the 2617.43s of remaining time.\n",
      "\t0.9895\t = Validation score   (roc_auc)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1730.5s of the 2614.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9863\t = Validation score   (roc_auc)\n",
      "\t71.08s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1658.11s of the 2542.31s of remaining time.\n",
      "\t0.9886\t = Validation score   (roc_auc)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1655.45s of the 2539.65s of remaining time.\n",
      "\t0.9891\t = Validation score   (roc_auc)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t1.59s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1652.72s of the 2536.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.97\t = Validation score   (roc_auc)\n",
      "\t60.47s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1590.66s of the 2474.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9866\t = Validation score   (roc_auc)\n",
      "\t16.57s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1572.64s of the 2456.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9741\t = Validation score   (roc_auc)\n",
      "\t163.47s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1407.84s of the 2292.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9876\t = Validation score   (roc_auc)\n",
      "\t10.91s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1395.54s of the 2279.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9859\t = Validation score   (roc_auc)\n",
      "\t42.45s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1351.71s of the 2235.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9753\t = Validation score   (roc_auc)\n",
      "\t279.17s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1071.16s of the 1955.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9875\t = Validation score   (roc_auc)\n",
      "\t26.0s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1043.46s of the 1927.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9699\t = Validation score   (roc_auc)\n",
      "\t144.27s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 897.78s of the 1781.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.14%)\n",
      "\t0.9867\t = Validation score   (roc_auc)\n",
      "\t44.5s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 851.97s of the 1736.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9836\t = Validation score   (roc_auc)\n",
      "\t40.29s\t = Training   runtime\n",
      "\t4.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 809.71s of the 1693.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9736\t = Validation score   (roc_auc)\n",
      "\t250.74s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 557.59s of the 1441.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.25%)\n",
      "\t0.9877\t = Validation score   (roc_auc)\n",
      "\t31.24s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 524.84s of the 1409.04s of remaining time.\n",
      "\t0.9888\t = Validation score   (roc_auc)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 522.28s of the 1406.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9847\t = Validation score   (roc_auc)\n",
      "\t103.23s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 417.69s of the 1301.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9709\t = Validation score   (roc_auc)\n",
      "\t22.89s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 393.43s of the 1277.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.14%)\n",
      "\t0.9866\t = Validation score   (roc_auc)\n",
      "\t174.83s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 217.18s of the 1101.38s of remaining time.\n",
      "\t0.9872\t = Validation score   (roc_auc)\n",
      "\t3.95s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 212.04s of the 1096.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9859\t = Validation score   (roc_auc)\n",
      "\t19.52s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 191.05s of the 1075.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.962\t = Validation score   (roc_auc)\n",
      "\t126.29s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 63.27s of the 947.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9867\t = Validation score   (roc_auc)\n",
      "\t24.42s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 37.45s of the 921.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.96\t = Validation score   (roc_auc)\n",
      "\t29.52s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 6.62s of the 890.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9872\t = Validation score   (roc_auc)\n",
      "\t5.48s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 883.91s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestGini_BAG_L1': 0.217, 'ExtraTreesEntr_BAG_L1': 0.2, 'ExtraTreesGini_BAG_L1': 0.183, 'RandomForestEntr_BAG_L1': 0.167, 'RandomForest_r195_BAG_L1': 0.083, 'LightGBM_BAG_L1': 0.033, 'NeuralNetTorch_BAG_L1': 0.033, 'LightGBM_r131_BAG_L1': 0.033, 'NeuralNetTorch_r22_BAG_L1': 0.033, 'LightGBMLarge_BAG_L1': 0.017}\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t15.71s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 868.17s of the 868.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.9921\t = Validation score   (roc_auc)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 864.67s of the 864.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.992\t = Validation score   (roc_auc)\n",
      "\t2.27s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 860.99s of the 860.93s of remaining time.\n",
      "\t0.986\t = Validation score   (roc_auc)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t2.37s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 856.69s of the 856.63s of remaining time.\n",
      "\t0.9876\t = Validation score   (roc_auc)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t2.82s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 852.29s of the 852.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.9923\t = Validation score   (roc_auc)\n",
      "\t4.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 846.08s of the 846.02s of remaining time.\n",
      "\t0.9865\t = Validation score   (roc_auc)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t2.42s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 842.48s of the 842.42s of remaining time.\n",
      "\t0.9871\t = Validation score   (roc_auc)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 839.73s of the 839.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9904\t = Validation score   (roc_auc)\n",
      "\t59.56s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 778.72s of the 778.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t2.99s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 774.27s of the 774.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t48.79s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 723.99s of the 723.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9894\t = Validation score   (roc_auc)\n",
      "\t4.34s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 718.22s of the 718.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.14%)\n",
      "\t0.9924\t = Validation score   (roc_auc)\n",
      "\t5.16s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 711.7s of the 711.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.99\t = Validation score   (roc_auc)\n",
      "\t73.82s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 636.4s of the 636.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t6.33s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 628.64s of the 628.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9887\t = Validation score   (roc_auc)\n",
      "\t113.56s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 513.49s of the 513.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.23%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t12.41s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 499.66s of the 499.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.9924\t = Validation score   (roc_auc)\n",
      "\t9.67s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 488.52s of the 488.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9916\t = Validation score   (roc_auc)\n",
      "\t102.11s\t = Training   runtime\n",
      "\t1.0s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 384.86s of the 384.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.40%)\n",
      "\t0.9918\t = Validation score   (roc_auc)\n",
      "\t13.33s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 370.1s of the 370.04s of remaining time.\n",
      "\t0.9862\t = Validation score   (roc_auc)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t2.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 366.08s of the 366.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t7.92s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 356.75s of the 356.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9909\t = Validation score   (roc_auc)\n",
      "\t23.15s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 332.2s of the 332.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.24%)\n",
      "\t0.9925\t = Validation score   (roc_auc)\n",
      "\t28.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 302.77s of the 302.71s of remaining time.\n",
      "\t0.9838\t = Validation score   (roc_auc)\n",
      "\t10.18s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 290.84s of the 290.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9916\t = Validation score   (roc_auc)\n",
      "\t5.1s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 284.36s of the 284.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9884\t = Validation score   (roc_auc)\n",
      "\t131.93s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 150.81s of the 150.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t3.14s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 146.27s of the 146.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9906\t = Validation score   (roc_auc)\n",
      "\t116.83s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 27.98s of the 27.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9912\t = Validation score   (roc_auc)\n",
      "\t2.6s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 24.03s of the 23.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9915\t = Validation score   (roc_auc)\n",
      "\t19.97s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 2.18s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.333, 'NeuralNetTorch_r22_BAG_L2': 0.141, 'CatBoost_r13_BAG_L2': 0.103, 'NeuralNetTorch_r86_BAG_L2': 0.103, 'XGBoost_BAG_L2': 0.09, 'NeuralNetFastAI_BAG_L2': 0.064, 'LightGBM_BAG_L2': 0.051, 'LightGBM_r131_BAG_L2': 0.051, 'RandomForestGini_BAG_L1': 0.013, 'RandomForestEntr_BAG_L1': 0.013, 'ExtraTreesEntr_BAG_L1': 0.013, 'LightGBM_r96_BAG_L2': 0.013, 'LightGBM_r188_BAG_L2': 0.013}\n",
      "\t0.9929\t = Validation score   (roc_auc)\n",
      "\t15.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2665.81s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClassPredictor_label0\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: agModels-predictClassPredictor_label1/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: label1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 923 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2677 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2677s\n",
      "AutoGluon will save models to \"agModels-predictClassPredictor_label1\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #112-Ubuntu SMP Tue Mar 5 16:50:32 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       97.27 GB / 125.73 GB (77.4%)\n",
      "Disk Space Avail:   17.07 GB / 97.87 GB (17.4%)\n",
      "===================================================\n",
      "Train Data Rows:    61118\n",
      "Train Data Columns: 83\n",
      "Label Column:       label1\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    99618.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.14 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 67 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 23): ['D', 'H', 'M', 'Q', 'S', 'T', 'U', 'V', 'W', 'X', '100.0', '109.0', '111.0', '112.0', '113.0', '115.0', '117.0', '118.0', '125.0', '126.0', '127.0', '129.0', '132.0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('bool', []) : 23 | ['D', 'H', 'M', 'Q', 'S', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 43 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t\t('float', []) : 16 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])   :  1 | ['Exclamations']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])       :  1 | ['Exclamations']\n",
      "\t\t('int', ['bool']) : 44 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t60 features in original data used to generate 60 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.39 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.7s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1783.75s of the 2676.29s of remaining time.\n",
      "\t0.9807\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1783.12s of the 2675.65s of remaining time.\n",
      "\t0.9823\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1782.48s of the 2675.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t11.08s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1769.99s of the 2662.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9921\t = Validation score   (roc_auc)\n",
      "\t5.79s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1762.78s of the 2655.32s of remaining time.\n",
      "\t0.9925\t = Validation score   (roc_auc)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1760.07s of the 2652.6s of remaining time.\n",
      "\t0.9927\t = Validation score   (roc_auc)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t1.44s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1757.45s of the 2649.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t56.07s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1700.03s of the 2592.56s of remaining time.\n",
      "\t0.9927\t = Validation score   (roc_auc)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t1.89s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1696.76s of the 2589.3s of remaining time.\n",
      "\t0.9925\t = Validation score   (roc_auc)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t1.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1693.61s of the 2586.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9895\t = Validation score   (roc_auc)\n",
      "\t45.26s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1646.77s of the 2539.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t8.13s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1637.3s of the 2529.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9897\t = Validation score   (roc_auc)\n",
      "\t68.8s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1567.09s of the 2459.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t8.73s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1556.92s of the 2449.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9916\t = Validation score   (roc_auc)\n",
      "\t38.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1517.56s of the 2410.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9896\t = Validation score   (roc_auc)\n",
      "\t112.85s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1403.33s of the 2295.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t17.57s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1384.08s of the 2276.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9894\t = Validation score   (roc_auc)\n",
      "\t104.07s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1278.53s of the 2171.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.14%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t41.48s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1235.7s of the 2128.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9916\t = Validation score   (roc_auc)\n",
      "\t29.88s\t = Training   runtime\n",
      "\t3.82s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1203.87s of the 2096.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9893\t = Validation score   (roc_auc)\n",
      "\t124.24s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1078.22s of the 1970.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.25%)\n",
      "\t0.9923\t = Validation score   (roc_auc)\n",
      "\t19.67s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1057.06s of the 1949.6s of remaining time.\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1054.38s of the 1946.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9909\t = Validation score   (roc_auc)\n",
      "\t101.8s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 951.27s of the 1843.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9895\t = Validation score   (roc_auc)\n",
      "\t17.49s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 932.37s of the 1824.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t147.31s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 783.69s of the 1676.23s of remaining time.\n",
      "\t0.9918\t = Validation score   (roc_auc)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 778.29s of the 1670.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9921\t = Validation score   (roc_auc)\n",
      "\t12.14s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 764.62s of the 1657.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.989\t = Validation score   (roc_auc)\n",
      "\t104.55s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 658.52s of the 1551.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t14.35s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 642.7s of the 1535.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9895\t = Validation score   (roc_auc)\n",
      "\t188.48s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 452.82s of the 1345.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t7.57s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 443.81s of the 1336.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9896\t = Validation score   (roc_auc)\n",
      "\t100.4s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 342.02s of the 1234.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9911\t = Validation score   (roc_auc)\n",
      "\t46.18s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 294.51s of the 1187.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9867\t = Validation score   (roc_auc)\n",
      "\t85.93s\t = Training   runtime\n",
      "\t1.0s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 207.06s of the 1099.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.9918\t = Validation score   (roc_auc)\n",
      "\t5.64s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 200.08s of the 1092.61s of remaining time.\n",
      "\t0.9912\t = Validation score   (roc_auc)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 197.4s of the 1089.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9914\t = Validation score   (roc_auc)\n",
      "\t81.98s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 114.02s of the 1006.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9884\t = Validation score   (roc_auc)\n",
      "\t55.39s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 57.15s of the 949.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9894\t = Validation score   (roc_auc)\n",
      "\t37.7s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 18.13s of the 910.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.14%)\n",
      "\t0.9923\t = Validation score   (roc_auc)\n",
      "\t14.91s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 1.55s of the 894.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9851\t = Validation score   (roc_auc)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 890.1s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestGini_BAG_L1': 0.184, 'RandomForestEntr_BAG_L1': 0.184, 'LightGBM_r188_BAG_L1': 0.122, 'ExtraTreesGini_BAG_L1': 0.102, 'ExtraTreesEntr_BAG_L1': 0.102, 'XGBoost_r33_BAG_L1': 0.102, 'CatBoost_BAG_L1': 0.061, 'CatBoost_r13_BAG_L1': 0.061, 'NeuralNetTorch_r86_BAG_L1': 0.041, 'ExtraTrees_r42_BAG_L1': 0.02, 'XGBoost_r89_BAG_L1': 0.02}\n",
      "\t0.9934\t = Validation score   (roc_auc)\n",
      "\t16.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 873.99s of the 873.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t2.34s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 870.18s of the 870.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 866.65s of the 866.57s of remaining time.\n",
      "\t0.9935\t = Validation score   (roc_auc)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t2.92s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 861.4s of the 861.33s of remaining time.\n",
      "\t0.9937\t = Validation score   (roc_auc)\n",
      "\t1.92s\t = Training   runtime\n",
      "\t2.78s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 856.5s of the 856.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t17.66s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 837.44s of the 837.35s of remaining time.\n",
      "\t0.9937\t = Validation score   (roc_auc)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t2.68s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 833.45s of the 833.37s of remaining time.\n",
      "\t0.9937\t = Validation score   (roc_auc)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t2.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 829.76s of the 829.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.20%)\n",
      "\t0.9939\t = Validation score   (roc_auc)\n",
      "\t46.32s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 781.94s of the 781.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 776.75s of the 776.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.994\t = Validation score   (roc_auc)\n",
      "\t45.18s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 730.07s of the 729.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 723.7s of the 723.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t10.73s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 711.54s of the 711.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.9939\t = Validation score   (roc_auc)\n",
      "\t70.48s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 639.59s of the 639.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9944\t = Validation score   (roc_auc)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 632.08s of the 632.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.20%)\n",
      "\t0.9935\t = Validation score   (roc_auc)\n",
      "\t105.51s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 525.04s of the 524.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.27%)\n",
      "\t0.9944\t = Validation score   (roc_auc)\n",
      "\t21.22s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 502.37s of the 502.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t8.13s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 492.59s of the 492.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.9939\t = Validation score   (roc_auc)\n",
      "\t92.79s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 398.34s of the 398.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.45%)\n",
      "\t0.9945\t = Validation score   (roc_auc)\n",
      "\t16.78s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 380.05s of the 379.96s of remaining time.\n",
      "\t0.9936\t = Validation score   (roc_auc)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t2.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 375.8s of the 375.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t21.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 353.2s of the 353.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.20%)\n",
      "\t0.9939\t = Validation score   (roc_auc)\n",
      "\t22.79s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 328.99s of the 328.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.27%)\n",
      "\t0.9944\t = Validation score   (roc_auc)\n",
      "\t65.74s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 261.77s of the 261.7s of remaining time.\n",
      "\t0.9935\t = Validation score   (roc_auc)\n",
      "\t15.69s\t = Training   runtime\n",
      "\t2.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 243.69s of the 243.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 238.56s of the 238.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.20%)\n",
      "\t0.9936\t = Validation score   (roc_auc)\n",
      "\t95.12s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 141.83s of the 141.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t3.71s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 136.73s of the 136.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.9932\t = Validation score   (roc_auc)\n",
      "\t106.42s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 28.88s of the 28.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.17%)\n",
      "\t0.9943\t = Validation score   (roc_auc)\n",
      "\t3.44s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 23.97s of the 23.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.9939\t = Validation score   (roc_auc)\n",
      "\t20.02s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 1.94s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_r33_BAG_L2': 0.258, 'NeuralNetTorch_r22_BAG_L2': 0.194, 'NeuralNetFastAI_BAG_L2': 0.129, 'LightGBMLarge_BAG_L2': 0.097, 'NeuralNetTorch_r79_BAG_L2': 0.097, 'RandomForest_r195_BAG_L2': 0.065, 'NeuralNetTorch_r86_BAG_L2': 0.065, 'NeuralNetTorch_BAG_L2': 0.032, 'ExtraTrees_r42_BAG_L2': 0.032, 'CatBoost_r13_BAG_L2': 0.032}\n",
      "\t0.9948\t = Validation score   (roc_auc)\n",
      "\t16.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2691.19s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClassPredictor_label1\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: agModels-predictClassPredictor_label2/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: label2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 918 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2682 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 2682s\n",
      "AutoGluon will save models to \"agModels-predictClassPredictor_label2\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #112-Ubuntu SMP Tue Mar 5 16:50:32 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       97.33 GB / 125.73 GB (77.4%)\n",
      "Disk Space Avail:   13.72 GB / 97.87 GB (14.0%)\n",
      "===================================================\n",
      "Train Data Rows:    61118\n",
      "Train Data Columns: 84\n",
      "Label Column:       label2\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    99678.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.61 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 68 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 23): ['D', 'H', 'M', 'Q', 'S', 'T', 'U', 'V', 'W', 'X', '100.0', '109.0', '111.0', '112.0', '113.0', '115.0', '117.0', '118.0', '125.0', '126.0', '127.0', '129.0', '132.0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('bool', []) : 23 | ['D', 'H', 'M', 'Q', 'S', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 43 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t\t('float', []) : 17 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])   :  1 | ['Exclamations']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])       :  1 | ['Exclamations']\n",
      "\t\t('int', ['bool']) : 45 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t61 features in original data used to generate 61 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.45 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.72s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2681.28s of the 2681.27s of remaining time.\n",
      "\t0.942\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2680.65s of the 2680.65s of remaining time.\n",
      "\t0.9466\t = Validation score   (roc_auc)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2680.07s of the 2680.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9905\t = Validation score   (roc_auc)\n",
      "\t9.23s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2669.4s of the 2669.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9916\t = Validation score   (roc_auc)\n",
      "\t3.84s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2664.27s of the 2664.26s of remaining time.\n",
      "\t0.9893\t = Validation score   (roc_auc)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2662.14s of the 2662.14s of remaining time.\n",
      "\t0.9914\t = Validation score   (roc_auc)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2660.04s of the 2660.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9911\t = Validation score   (roc_auc)\n",
      "\t51.55s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2607.12s of the 2607.12s of remaining time.\n",
      "\t0.9905\t = Validation score   (roc_auc)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2604.99s of the 2604.98s of remaining time.\n",
      "\t0.9911\t = Validation score   (roc_auc)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2602.56s of the 2602.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9825\t = Validation score   (roc_auc)\n",
      "\t43.54s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2557.39s of the 2557.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9908\t = Validation score   (roc_auc)\n",
      "\t6.3s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2549.68s of the 2549.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9815\t = Validation score   (roc_auc)\n",
      "\t83.79s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2464.5s of the 2464.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9899\t = Validation score   (roc_auc)\n",
      "\t3.7s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 2459.45s of the 2459.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9909\t = Validation score   (roc_auc)\n",
      "\t27.12s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 2430.98s of the 2430.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9826\t = Validation score   (roc_auc)\n",
      "\t107.65s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 2321.98s of the 2321.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9921\t = Validation score   (roc_auc)\n",
      "\t8.5s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 2311.92s of the 2311.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9781\t = Validation score   (roc_auc)\n",
      "\t103.54s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 2206.88s of the 2206.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t23.17s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 2182.34s of the 2182.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9902\t = Validation score   (roc_auc)\n",
      "\t33.29s\t = Training   runtime\n",
      "\t3.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 2147.08s of the 2147.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9852\t = Validation score   (roc_auc)\n",
      "\t150.81s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1994.87s of the 1994.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.25%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t15.6s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1977.85s of the 1977.84s of remaining time.\n",
      "\t0.9862\t = Validation score   (roc_auc)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t1.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1975.74s of the 1975.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9906\t = Validation score   (roc_auc)\n",
      "\t107.17s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 1867.24s of the 1867.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9855\t = Validation score   (roc_auc)\n",
      "\t20.39s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 1845.45s of the 1845.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9909\t = Validation score   (roc_auc)\n",
      "\t105.53s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 1738.55s of the 1738.54s of remaining time.\n",
      "\t0.9849\t = Validation score   (roc_auc)\n",
      "\t3.31s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 1734.08s of the 1734.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9908\t = Validation score   (roc_auc)\n",
      "\t8.63s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 1724.04s of the 1724.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9698\t = Validation score   (roc_auc)\n",
      "\t96.04s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 1626.56s of the 1626.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.991\t = Validation score   (roc_auc)\n",
      "\t10.66s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1614.52s of the 1614.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9797\t = Validation score   (roc_auc)\n",
      "\t196.64s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 1416.45s of the 1416.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9914\t = Validation score   (roc_auc)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1411.76s of the 1411.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9827\t = Validation score   (roc_auc)\n",
      "\t154.88s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 1255.47s of the 1255.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9895\t = Validation score   (roc_auc)\n",
      "\t28.66s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 1225.46s of the 1225.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9568\t = Validation score   (roc_auc)\n",
      "\t86.35s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 1137.58s of the 1137.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.9914\t = Validation score   (roc_auc)\n",
      "\t4.99s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 1131.26s of the 1131.26s of remaining time.\n",
      "\t0.9883\t = Validation score   (roc_auc)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 1128.97s of the 1128.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9915\t = Validation score   (roc_auc)\n",
      "\t38.1s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 1089.61s of the 1089.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9692\t = Validation score   (roc_auc)\n",
      "\t83.63s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 1004.61s of the 1004.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.979\t = Validation score   (roc_auc)\n",
      "\t60.22s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 943.01s of the 943.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.14%)\n",
      "\t0.9893\t = Validation score   (roc_auc)\n",
      "\t10.96s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 930.61s of the 930.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9688\t = Validation score   (roc_auc)\n",
      "\t31.68s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 897.51s of the 897.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9902\t = Validation score   (roc_auc)\n",
      "\t23.93s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 872.19s of the 872.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9848\t = Validation score   (roc_auc)\n",
      "\t26.99s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 843.85s of the 843.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9905\t = Validation score   (roc_auc)\n",
      "\t49.0s\t = Training   runtime\n",
      "\t4.57s\t = Validation runtime\n",
      "Fitting model: RandomForest_r39_BAG_L1 ... Training model for up to 791.79s of the 791.79s of remaining time.\n",
      "\t0.9856\t = Validation score   (roc_auc)\n",
      "\t3.31s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: CatBoost_r167_BAG_L1 ... Training model for up to 787.34s of the 787.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9904\t = Validation score   (roc_auc)\n",
      "\t23.3s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r95_BAG_L1 ... Training model for up to 762.74s of the 762.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9689\t = Validation score   (roc_auc)\n",
      "\t98.85s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r41_BAG_L1 ... Training model for up to 662.4s of the 662.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9814\t = Validation score   (roc_auc)\n",
      "\t118.66s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_r98_BAG_L1 ... Training model for up to 542.41s of the 542.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.16%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t39.09s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_r15_BAG_L1 ... Training model for up to 501.73s of the 501.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t9.12s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r158_BAG_L1 ... Training model for up to 491.12s of the 491.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9459\t = Validation score   (roc_auc)\n",
      "\t134.3s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: CatBoost_r86_BAG_L1 ... Training model for up to 355.47s of the 355.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9913\t = Validation score   (roc_auc)\n",
      "\t33.49s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r37_BAG_L1 ... Training model for up to 320.59s of the 320.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9708\t = Validation score   (roc_auc)\n",
      "\t54.35s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r197_BAG_L1 ... Training model for up to 264.89s of the 264.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9762\t = Validation score   (roc_auc)\n",
      "\t63.11s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_r49_BAG_L1 ... Training model for up to 200.43s of the 200.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9901\t = Validation score   (roc_auc)\n",
      "\t73.53s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r49_BAG_L1 ... Training model for up to 125.55s of the 125.54s of remaining time.\n",
      "\t0.9905\t = Validation score   (roc_auc)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_r143_BAG_L1 ... Training model for up to 122.94s of the 122.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.9879\t = Validation score   (roc_auc)\n",
      "\t9.11s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForest_r127_BAG_L1 ... Training model for up to 112.49s of the 112.48s of remaining time.\n",
      "\t0.984\t = Validation score   (roc_auc)\n",
      "\t4.18s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r134_BAG_L1 ... Training model for up to 107.14s of the 107.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9864\t = Validation score   (roc_auc)\n",
      "\t67.63s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: RandomForest_r34_BAG_L1 ... Training model for up to 38.2s of the 38.19s of remaining time.\n",
      "\t0.9816\t = Validation score   (roc_auc)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: LightGBM_r94_BAG_L1 ... Training model for up to 34.41s of the 34.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9903\t = Validation score   (roc_auc)\n",
      "\t17.35s\t = Training   runtime\n",
      "\t1.45s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r143_BAG_L1 ... Training model for up to 15.53s of the 15.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9634\t = Validation score   (roc_auc)\n",
      "\t12.65s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1.41s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r69_BAG_L1': 0.422, 'LightGBM_BAG_L1': 0.193, 'ExtraTreesEntr_BAG_L1': 0.157, 'RandomForestEntr_BAG_L1': 0.145, 'NeuralNetFastAI_r102_BAG_L1': 0.072, 'LightGBM_r131_BAG_L1': 0.012}\n",
      "\t0.9951\t = Validation score   (roc_auc)\n",
      "\t15.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2696.23s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClassPredictor_label2\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: agModels-predictClassPredictor_label3/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: label3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 922 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2678 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2678s\n",
      "AutoGluon will save models to \"agModels-predictClassPredictor_label3\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #112-Ubuntu SMP Tue Mar 5 16:50:32 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       97.20 GB / 125.73 GB (77.3%)\n",
      "Disk Space Avail:   11.71 GB / 97.87 GB (12.0%)\n",
      "===================================================\n",
      "Train Data Rows:    61118\n",
      "Train Data Columns: 85\n",
      "Label Column:       label3\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    99540.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.07 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 69 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 23): ['D', 'H', 'M', 'Q', 'S', 'T', 'U', 'V', 'W', 'X', '100.0', '109.0', '111.0', '112.0', '113.0', '115.0', '117.0', '118.0', '125.0', '126.0', '127.0', '129.0', '132.0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('bool', []) : 23 | ['D', 'H', 'M', 'Q', 'S', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 43 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t\t('float', []) : 18 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])   :  1 | ['Exclamations']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])       :  1 | ['Exclamations']\n",
      "\t\t('int', ['bool']) : 46 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t62 features in original data used to generate 62 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.51 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.74s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1784.39s of the 2677.25s of remaining time.\n",
      "\t0.9675\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1783.86s of the 2676.72s of remaining time.\n",
      "\t0.9712\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1783.37s of the 2676.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9917\t = Validation score   (roc_auc)\n",
      "\t9.07s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1772.81s of the 2665.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.992\t = Validation score   (roc_auc)\n",
      "\t4.54s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1766.91s of the 2659.77s of remaining time.\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1764.61s of the 2657.47s of remaining time.\n",
      "\t0.9911\t = Validation score   (roc_auc)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1762.38s of the 2655.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9921\t = Validation score   (roc_auc)\n",
      "\t53.54s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1707.53s of the 2600.4s of remaining time.\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1705.06s of the 2597.92s of remaining time.\n",
      "\t0.9925\t = Validation score   (roc_auc)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1702.58s of the 2595.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9876\t = Validation score   (roc_auc)\n",
      "\t46.28s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1654.75s of the 2547.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t6.67s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1646.7s of the 2539.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.987\t = Validation score   (roc_auc)\n",
      "\t89.24s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1556.14s of the 2449.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1549.95s of the 2442.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t35.53s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1513.08s of the 2405.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9879\t = Validation score   (roc_auc)\n",
      "\t156.22s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1355.48s of the 2248.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9925\t = Validation score   (roc_auc)\n",
      "\t11.47s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1342.52s of the 2235.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9847\t = Validation score   (roc_auc)\n",
      "\t93.57s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1247.5s of the 2140.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9927\t = Validation score   (roc_auc)\n",
      "\t32.33s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 1213.8s of the 2106.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9911\t = Validation score   (roc_auc)\n",
      "\t27.83s\t = Training   runtime\n",
      "\t3.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 1183.93s of the 2076.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.989\t = Validation score   (roc_auc)\n",
      "\t152.95s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 1029.61s of the 1922.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.26%)\n",
      "\t0.9925\t = Validation score   (roc_auc)\n",
      "\t18.49s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 1009.65s of the 1902.51s of remaining time.\n",
      "\t0.991\t = Validation score   (roc_auc)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 1007.19s of the 1900.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9915\t = Validation score   (roc_auc)\n",
      "\t102.54s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 903.32s of the 1796.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9882\t = Validation score   (roc_auc)\n",
      "\t17.77s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 884.2s of the 1777.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t167.63s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 715.17s of the 1608.03s of remaining time.\n",
      "\t0.9898\t = Validation score   (roc_auc)\n",
      "\t3.66s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 710.24s of the 1603.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9918\t = Validation score   (roc_auc)\n",
      "\t8.78s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 700.06s of the 1592.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.981\t = Validation score   (roc_auc)\n",
      "\t91.57s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 606.95s of the 1499.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.992\t = Validation score   (roc_auc)\n",
      "\t10.82s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 594.74s of the 1487.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9876\t = Validation score   (roc_auc)\n",
      "\t211.66s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 381.66s of the 1274.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9925\t = Validation score   (roc_auc)\n",
      "\t4.38s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 375.95s of the 1268.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9879\t = Validation score   (roc_auc)\n",
      "\t172.05s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 202.53s of the 1095.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9913\t = Validation score   (roc_auc)\n",
      "\t35.81s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 165.31s of the 1058.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9742\t = Validation score   (roc_auc)\n",
      "\t93.36s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 70.47s of the 963.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.9922\t = Validation score   (roc_auc)\n",
      "\t5.88s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 63.22s of the 956.08s of remaining time.\n",
      "\t0.9904\t = Validation score   (roc_auc)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 60.8s of the 953.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t48.73s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 10.77s of the 903.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9782\t = Validation score   (roc_auc)\n",
      "\t9.73s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 892.46s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r9_BAG_L1': 0.521, 'CatBoost_BAG_L1': 0.115, 'XGBoost_r33_BAG_L1': 0.083, 'ExtraTreesEntr_BAG_L1': 0.073, 'RandomForestGini_BAG_L1': 0.062, 'NeuralNetTorch_r22_BAG_L1': 0.062, 'CatBoost_r177_BAG_L1': 0.042, 'ExtraTrees_r42_BAG_L1': 0.031, 'RandomForestEntr_BAG_L1': 0.01}\n",
      "\t0.9948\t = Validation score   (roc_auc)\n",
      "\t15.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 876.7s of the 876.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.9955\t = Validation score   (roc_auc)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 873.26s of the 873.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.13%)\n",
      "\t0.995\t = Validation score   (roc_auc)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 869.91s of the 869.83s of remaining time.\n",
      "\t0.9897\t = Validation score   (roc_auc)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t3.4s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 864.63s of the 864.56s of remaining time.\n",
      "\t0.9899\t = Validation score   (roc_auc)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t2.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 860.81s of the 860.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9954\t = Validation score   (roc_auc)\n",
      "\t7.24s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 852.19s of the 852.12s of remaining time.\n",
      "\t0.9918\t = Validation score   (roc_auc)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t2.84s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 848.2s of the 848.13s of remaining time.\n",
      "\t0.992\t = Validation score   (roc_auc)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t2.75s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 844.33s of the 844.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9931\t = Validation score   (roc_auc)\n",
      "\t45.91s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 796.93s of the 796.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9953\t = Validation score   (roc_auc)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 792.78s of the 792.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.11%)\n",
      "\t0.9955\t = Validation score   (roc_auc)\n",
      "\t40.35s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 750.97s of the 750.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9932\t = Validation score   (roc_auc)\n",
      "\t4.26s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 745.34s of the 745.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.15%)\n",
      "\t0.9954\t = Validation score   (roc_auc)\n",
      "\t5.93s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 738.03s of the 737.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9947\t = Validation score   (roc_auc)\n",
      "\t65.6s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 670.9s of the 670.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.14%)\n",
      "\t0.9953\t = Validation score   (roc_auc)\n",
      "\t7.66s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 661.8s of the 661.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9929\t = Validation score   (roc_auc)\n",
      "\t102.88s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 557.36s of the 557.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.26%)\n",
      "\t0.9952\t = Validation score   (roc_auc)\n",
      "\t11.19s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L2 ... Training model for up to 544.72s of the 544.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.9955\t = Validation score   (roc_auc)\n",
      "\t6.79s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L2 ... Training model for up to 536.46s of the 536.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9951\t = Validation score   (roc_auc)\n",
      "\t150.57s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L2 ... Training model for up to 384.37s of the 384.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.45%)\n",
      "\t0.9951\t = Validation score   (roc_auc)\n",
      "\t13.04s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L2 ... Training model for up to 369.9s of the 369.82s of remaining time.\n",
      "\t0.9907\t = Validation score   (roc_auc)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t2.24s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L2 ... Training model for up to 365.95s of the 365.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.12%)\n",
      "\t0.9951\t = Validation score   (roc_auc)\n",
      "\t6.19s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L2 ... Training model for up to 358.3s of the 358.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.995\t = Validation score   (roc_auc)\n",
      "\t20.82s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L2 ... Training model for up to 336.08s of the 336.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.26%)\n",
      "\t0.9955\t = Validation score   (roc_auc)\n",
      "\t27.59s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L2 ... Training model for up to 307.07s of the 306.99s of remaining time.\n",
      "\t0.9899\t = Validation score   (roc_auc)\n",
      "\t11.81s\t = Training   runtime\n",
      "\t2.52s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L2 ... Training model for up to 292.55s of the 292.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9949\t = Validation score   (roc_auc)\n",
      "\t4.27s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ... Training model for up to 286.86s of the 286.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.19%)\n",
      "\t0.9928\t = Validation score   (roc_auc)\n",
      "\t109.13s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L2 ... Training model for up to 176.13s of the 176.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.18%)\n",
      "\t0.9956\t = Validation score   (roc_auc)\n",
      "\t2.81s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L2 ... Training model for up to 171.92s of the 171.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9942\t = Validation score   (roc_auc)\n",
      "\t106.53s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L2 ... Training model for up to 63.95s of the 63.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.16%)\n",
      "\t0.9944\t = Validation score   (roc_auc)\n",
      "\t3.22s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L2 ... Training model for up to 59.33s of the 59.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9952\t = Validation score   (roc_auc)\n",
      "\t48.16s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 9.16s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L2': 0.255, 'NeuralNetFastAI_r102_BAG_L2': 0.218, 'NeuralNetTorch_r86_BAG_L2': 0.2, 'NeuralNetTorch_r22_BAG_L2': 0.109, 'XGBoost_r89_BAG_L2': 0.073, 'LightGBM_BAG_L2': 0.055, 'NeuralNetFastAI_BAG_L2': 0.055, 'NeuralNetTorch_r30_BAG_L2': 0.036}\n",
      "\t0.9962\t = Validation score   (roc_auc)\n",
      "\t15.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2684.52s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClassPredictor_label3\")\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: agModels-predictClassPredictor_label4/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: label4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 925 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2675 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2675s\n",
      "AutoGluon will save models to \"agModels-predictClassPredictor_label4\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #112-Ubuntu SMP Tue Mar 5 16:50:32 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       97.19 GB / 125.73 GB (77.3%)\n",
      "Disk Space Avail:   10.08 GB / 97.87 GB (10.3%)\n",
      "===================================================\n",
      "Train Data Rows:    61118\n",
      "Train Data Columns: 86\n",
      "Label Column:       label4\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    99529.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.54 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 70 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 23): ['D', 'H', 'M', 'Q', 'S', 'T', 'U', 'V', 'W', 'X', '100.0', '109.0', '111.0', '112.0', '113.0', '115.0', '117.0', '118.0', '125.0', '126.0', '127.0', '129.0', '132.0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('bool', []) : 23 | ['D', 'H', 'M', 'Q', 'S', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 43 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t\t('float', []) : 19 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])   :  1 | ['Exclamations']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])       :  1 | ['Exclamations']\n",
      "\t\t('int', ['bool']) : 47 | ['have_code', 'B', 'C', 'E', 'F', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t63 features in original data used to generate 63 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.57 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.73s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1782.4s of the 2674.26s of remaining time.\n",
      "\t0.9373\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1781.85s of the 2673.71s of remaining time.\n",
      "\t0.9393\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1781.35s of the 2673.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9927\t = Validation score   (roc_auc)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1775.09s of the 2666.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9924\t = Validation score   (roc_auc)\n",
      "\t2.49s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1771.24s of the 2663.1s of remaining time.\n",
      "\t0.9839\t = Validation score   (roc_auc)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1768.99s of the 2660.85s of remaining time.\n",
      "\t0.9844\t = Validation score   (roc_auc)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t1.22s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1766.77s of the 2658.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9919\t = Validation score   (roc_auc)\n",
      "\t30.75s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1734.72s of the 2626.58s of remaining time.\n",
      "\t0.9827\t = Validation score   (roc_auc)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1732.3s of the 2624.16s of remaining time.\n",
      "\t0.9849\t = Validation score   (roc_auc)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1729.59s of the 2621.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9907\t = Validation score   (roc_auc)\n",
      "\t46.69s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1681.29s of the 2573.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9918\t = Validation score   (roc_auc)\n",
      "\t4.79s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1675.12s of the 2566.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n",
      "\t0.9878\t = Validation score   (roc_auc)\n",
      "\t54.67s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1619.1s of the 2510.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.10%)\n",
      "\t0.9892\t = Validation score   (roc_auc)\n",
      "\t3.49s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1614.26s of the 2506.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9921\t = Validation score   (roc_auc)\n",
      "\t17.31s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1595.6s of the 2487.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n"
     ]
    }
   ],
   "source": [
    "predictor = MultilabelPredictor(labels=labels, problem_types=problem_types, eval_metrics=eval_metrics, path=save_path).fit(meta_dataset_train, presets='best_quality', time_limit=3600)\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=10, criterion=\"gini\", n_estimators=150, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=150)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=train_df.loc[:, train_df.columns != 'Категория'], y=train_df[\"Категория\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict(X=test_df.loc[:, train_df.columns != 'Категория'])\n",
    "gt_labels = test_df[\"Категория\"].values\n",
    "pred_labels = [id2label[x] for x in pred_labels]\n",
    "gt_labels = [id2label[x] for x in gt_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score      support\n",
      "Видео          0.938500  0.865975  0.900780  4335.000000\n",
      "ДЗ             0.962364  0.918466  0.939903  4538.000000\n",
      "Лонгрид        0.265690  0.622549  0.372434   408.000000\n",
      "Тест           0.824786  0.804167  0.814346   240.000000\n",
      "accuracy       0.879004  0.879004  0.879004     0.879004\n",
      "macro avg      0.747835  0.802789  0.756866  9521.000000\n",
      "weighted avg   0.918176  0.879004  0.894607  9521.000000\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(gt_labels, pred_labels, output_dict=True)\n",
    "cr = pd.DataFrame(cr).T\n",
    "print(cr)\n",
    "\n",
    "cm = confusion_matrix(gt_labels, pred_labels, labels=list(label2id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "reversescale": false,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "Видео",
          "ДЗ",
          "Лонгрид",
          "Тест"
         ],
         "y": [
          "Тест",
          "Лонгрид",
          "ДЗ",
          "Видео"
         ],
         "z": [
          [
           15,
           5,
           27,
           193
          ],
          [
           97,
           29,
           254,
           28
          ],
          [
           134,
           4168,
           228,
           8
          ],
          [
           3754,
           129,
           447,
           5
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "15",
          "x": "Видео",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "5",
          "x": "ДЗ",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "27",
          "x": "Лонгрид",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "193",
          "x": "Тест",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "97",
          "x": "Видео",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "29",
          "x": "ДЗ",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "254",
          "x": "Лонгрид",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "28",
          "x": "Тест",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "134",
          "x": "Видео",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "4168",
          "x": "ДЗ",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "228",
          "x": "Лонгрид",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "8",
          "x": "Тест",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "3754",
          "x": "Видео",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "129",
          "x": "ДЗ",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "447",
          "x": "Лонгрид",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "5",
          "x": "Тест",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "Predicted value",
          "x": 0.5,
          "xref": "paper",
          "y": -0.15,
          "yref": "paper"
         },
         {
          "showarrow": false,
          "text": "Real value",
          "textangle": -90,
          "x": -0.16,
          "xref": "paper",
          "y": 0.5,
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion matrix"
        },
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": ""
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  "
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "x = list(label2id.keys())\n",
    "y = list(reversed(label2id.keys()))\n",
    "fig = ff.create_annotated_heatmap(np.flipud(cm), x=x, y=y, colorscale=\"Viridis\")\n",
    "fig.update_layout(title_text=\"Confusion matrix\")\n",
    "fig.add_annotation(\n",
    "    dict(\n",
    "        x=0.5,\n",
    "        y=-0.15,\n",
    "        showarrow=False,\n",
    "        text=\"Predicted value\",\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    dict(\n",
    "        x=-0.16,\n",
    "        y=0.5,\n",
    "        showarrow=False,\n",
    "        text=\"Real value\",\n",
    "        textangle=-90,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig[\"data\"][0][\"showscale\"] = True\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2307\n",
       "                \n",
       "                    &plusmn; 0.2420\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.05%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1977\n",
       "                \n",
       "                    &plusmn; 0.2157\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1900\n",
       "                \n",
       "                    &plusmn; 0.2752\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1808\n",
       "                \n",
       "                    &plusmn; 0.2737\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0364\n",
       "                \n",
       "                    &plusmn; 0.0942\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Speech_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0330\n",
       "                \n",
       "                    &plusmn; 0.0774\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Оценка\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0312\n",
       "                \n",
       "                    &plusmn; 0.0638\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Neutral_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0236\n",
       "                \n",
       "                    &plusmn; 0.0336\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Positive_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0202\n",
       "                \n",
       "                    &plusmn; 0.0415\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Negative_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.99%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0087\n",
       "                \n",
       "                    &plusmn; 0.0238\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Exclamations\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0090\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Z\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "                    &plusmn; 0.0111\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                F\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0058\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                122.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0027\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                116.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0059\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Y\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0078\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Positive\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                103.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0035\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                R\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Negative\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                L\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.39%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 50 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=150)\", description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='3', weight=0.2307170893956611, std=0.1210054330856475, value=None), FeatureWeight(feature='0', weight=0.19774163103797826, std=0.10784942862928834, value=None), FeatureWeight(feature='1', weight=0.1900068565058053, std=0.13761824626795846, value=None), FeatureWeight(feature='2', weight=0.18077571595339764, std=0.13683658306610924, value=None), FeatureWeight(feature='Speech_NLP', weight=0.03643594020109274, std=0.047121069515174356, value=None), FeatureWeight(feature='Оценка', weight=0.03301745465035411, std=0.038677750916137295, value=None), FeatureWeight(feature='Neutral_NLP', weight=0.031219837342808025, std=0.03191723325745654, value=None), FeatureWeight(feature='Positive_NLP', weight=0.02362133819180187, std=0.016818812829129105, value=None), FeatureWeight(feature='Negative_NLP', weight=0.020206729353502494, std=0.02076402643141657, value=None), FeatureWeight(feature='Exclamations', weight=0.008656752166771944, std=0.01192172522835438, value=None), FeatureWeight(feature='Z', weight=0.0051492467913618195, std=0.004479782686568709, value=None), FeatureWeight(feature='F', weight=0.003843163354909346, std=0.005548738763783975, value=None), FeatureWeight(feature='122.0', weight=0.003208294438790977, std=0.0028989802203973586, value=None), FeatureWeight(feature='116.0', weight=0.002655952963172194, std=0.002632732121058257, value=None), FeatureWeight(feature='Y', weight=0.002641578596777077, std=0.002932957812592763, value=None), FeatureWeight(feature='Positive', weight=0.0020942764710965545, std=0.003896218220718816, value=None), FeatureWeight(feature='103.0', weight=0.002088955796174922, std=0.0014967015905626095, value=None), FeatureWeight(feature='R', weight=0.0019401956497559316, std=0.0017669000828721899, value=None), FeatureWeight(feature='Negative', weight=0.0018340849092393118, std=0.0033603694056714567, value=None), FeatureWeight(feature='L', weight=0.0015629090251714256, std=0.0020533570389643092, value=None)], remaining=50), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.explain_weights(model, target_names=id2label, feature_names=train_df.loc[:, train_df.columns != 'Категория'].columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
