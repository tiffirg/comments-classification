{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import seaborn as sns\n",
    "from typing import Any\n",
    "from functools import partial\n",
    "from datasets import load_dataset, Dataset\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation as PUNCT\n",
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    multilabel_confusion_matrix,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    hamming_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Направление</th><th>Факультет</th><th>ID студента</th><th>Оценка</th><th>Категория</th><th>Тег</th><th>Комментарий</th><th>Статус</th><th>Neutral</th><th>Positive</th><th>Negative</th><th>Exclamations</th><th>have_code</th><th>Neutral_NLP</th><th>Positive_NLP</th><th>Negative_NLP</th><th>Speech_NLP</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;C&quot;</td><td>113.0</td><td>1493.0</td><td>1.0</td><td>&quot;Видео&quot;</td><td>&quot;VP2&quot;</td><td>&quot;Видео лагает&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>1.00001</td><td>0.010663</td><td>0.00001</td><td>0.00001</td></tr><tr><td>&quot;C&quot;</td><td>113.0</td><td>5580.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Торгом Бабаян!…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5</td><td>false</td><td>0.437833</td><td>0.056662</td><td>0.140346</td><td>0.051855</td></tr><tr><td>&quot;E&quot;</td><td>126.0</td><td>5619.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3&quot;</td><td>&quot;Спасибо)&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.00001</td><td>0.00001</td><td>0.00001</td><td>1.00001</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>310.0</td><td>3.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H2 E1&quot;</td><td>&quot;комментарий со…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.930468</td><td>0.025189</td><td>0.119213</td><td>0.000378</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>1913.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Жонибек, хочу …</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2</td><td>false</td><td>0.069552</td><td>0.217348</td><td>0.019134</td><td>0.507822</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 17)\n",
       "┌────────────┬───────────┬────────────┬────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Направлени ┆ Факультет ┆ ID         ┆ Оценка ┆ … ┆ Neutral_N ┆ Positive_ ┆ Negative_ ┆ Speech_NL │\n",
       "│ е          ┆ ---       ┆ студента   ┆ ---    ┆   ┆ LP        ┆ NLP       ┆ NLP       ┆ P         │\n",
       "│ ---        ┆ f64       ┆ ---        ┆ f64    ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ str        ┆           ┆ f64        ┆        ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪════════════╪════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ C          ┆ 113.0     ┆ 1493.0     ┆ 1.0    ┆ … ┆ 1.00001   ┆ 0.010663  ┆ 0.00001   ┆ 0.00001   │\n",
       "│ C          ┆ 113.0     ┆ 5580.0     ┆ 5.0    ┆ … ┆ 0.437833  ┆ 0.056662  ┆ 0.140346  ┆ 0.051855  │\n",
       "│ E          ┆ 126.0     ┆ 5619.0     ┆ 5.0    ┆ … ┆ 0.00001   ┆ 0.00001   ┆ 0.00001   ┆ 1.00001   │\n",
       "│ E          ┆ 123.0     ┆ 310.0      ┆ 3.0    ┆ … ┆ 0.930468  ┆ 0.025189  ┆ 0.119213  ┆ 0.000378  │\n",
       "│ E          ┆ 123.0     ┆ 1913.0     ┆ 5.0    ┆ … ┆ 0.069552  ┆ 0.217348  ┆ 0.019134  ┆ 0.507822  │\n",
       "└────────────┴───────────┴────────────┴────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pl.read_csv(\"preprocessing.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_258, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Тег</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;S3 VC3 LMS&quot;</td><td>2</td></tr><tr><td>&quot;VP3 S1&quot;</td><td>20</td></tr><tr><td>&quot;VC2 S4&quot;</td><td>10</td></tr><tr><td>&quot;VC1 VP2 T1&quot;</td><td>1</td></tr><tr><td>&quot;H3 VC3 S1 VC2&quot;</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;S1 S3 S4&quot;</td><td>1</td></tr><tr><td>&quot;S3 VC1 VC2  S1…</td><td>1</td></tr><tr><td>&quot;VC2 H1 VC4&quot;</td><td>1</td></tr><tr><td>&quot;S3 VP3 VC2&quot;</td><td>2</td></tr><tr><td>&quot;E1 VC3 VP3 H3&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_258, 2)\n",
       "┌────────────────┬───────┐\n",
       "│ Тег            ┆ count │\n",
       "│ ---            ┆ ---   │\n",
       "│ str            ┆ u32   │\n",
       "╞════════════════╪═══════╡\n",
       "│ S3 VC3 LMS     ┆ 2     │\n",
       "│ VP3 S1         ┆ 20    │\n",
       "│ VC2 S4         ┆ 10    │\n",
       "│ VC1 VP2 T1     ┆ 1     │\n",
       "│ H3 VC3 S1 VC2  ┆ 1     │\n",
       "│ …              ┆ …     │\n",
       "│ S1 S3 S4       ┆ 1     │\n",
       "│ S3 VC1 VC2  S1 ┆ 1     │\n",
       "│ VC2 H1 VC4     ┆ 1     │\n",
       "│ S3 VP3 VC2     ┆ 2     │\n",
       "│ E1 VC3 VP3 H3  ┆ 1     │\n",
       "└────────────────┴───────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Тег\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_columns(\n",
    "    (pl.col(\"Тег\").apply(lambda x: \" \".join(re.findall(r\"[A-Z]{1,2}\\d|LMS\", x)))).alias(\"corrected_tag\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_filter = (\n",
    "    (pl.col(\"corrected_tag\").eq(\"\"))\n",
    ")\n",
    "\n",
    "dataset = dataset.filter(~null_filter)\n",
    "dataset = dataset.filter(~(pl.col(\"Комментарий\").is_null()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_columns(\n",
    "    pl.col(\"corrected_tag\")\n",
    "    .str.replace_all(r\"VC4|VP4|VC5|S4|T4|H4|EA1\", \"\")\n",
    "    .str.strip()\n",
    "    .str.replace(r\"\\s\\s+\", \" \")\n",
    "    .str.replace(r\"GH3\", \"H3\")\n",
    "    .str.replace(r\"HH3\", \"H3\")\n",
    "    .str.replace(r\"BP3\", \"VP3\")\n",
    "    .str.replace(r\"V3\", \"VC3\")\n",
    "    .str.replace(r\"V2\", \"VP2\")\n",
    ")\n",
    "\n",
    "dataset = dataset.filter(~(pl.col(\"corrected_tag\").eq(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (17, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>corrected_tag</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;H3&quot;</td><td>20391</td></tr><tr><td>&quot;VC2&quot;</td><td>14414</td></tr><tr><td>&quot;VC3&quot;</td><td>8111</td></tr><tr><td>&quot;VP3&quot;</td><td>4972</td></tr><tr><td>&quot;VP2&quot;</td><td>4897</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;LMS&quot;</td><td>669</td></tr><tr><td>&quot;T2&quot;</td><td>548</td></tr><tr><td>&quot;T1&quot;</td><td>399</td></tr><tr><td>&quot;T3&quot;</td><td>234</td></tr><tr><td>&quot;E2&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (17, 2)\n",
       "┌───────────────┬───────┐\n",
       "│ corrected_tag ┆ count │\n",
       "│ ---           ┆ ---   │\n",
       "│ str           ┆ u32   │\n",
       "╞═══════════════╪═══════╡\n",
       "│ H3            ┆ 20391 │\n",
       "│ VC2           ┆ 14414 │\n",
       "│ VC3           ┆ 8111  │\n",
       "│ VP3           ┆ 4972  │\n",
       "│ VP2           ┆ 4897  │\n",
       "│ …             ┆ …     │\n",
       "│ LMS           ┆ 669   │\n",
       "│ T2            ┆ 548   │\n",
       "│ T1            ┆ 399   │\n",
       "│ T3            ┆ 234   │\n",
       "│ E2            ┆ 1     │\n",
       "└───────────────┴───────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"corrected_tag\"].str.split(by = \" \").explode().value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(~pl.col(\"corrected_tag\").str.contains(\"E2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>corrected_tag</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;VC&quot;</td><td>26304</td></tr><tr><td>&quot;H&quot;</td><td>24437</td></tr><tr><td>&quot;VP&quot;</td><td>11560</td></tr><tr><td>&quot;S&quot;</td><td>1973</td></tr><tr><td>&quot;E&quot;</td><td>1785</td></tr><tr><td>&quot;T&quot;</td><td>1181</td></tr><tr><td>&quot;LMS&quot;</td><td>669</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌───────────────┬───────┐\n",
       "│ corrected_tag ┆ count │\n",
       "│ ---           ┆ ---   │\n",
       "│ str           ┆ u32   │\n",
       "╞═══════════════╪═══════╡\n",
       "│ VC            ┆ 26304 │\n",
       "│ H             ┆ 24437 │\n",
       "│ VP            ┆ 11560 │\n",
       "│ S             ┆ 1973  │\n",
       "│ E             ┆ 1785  │\n",
       "│ T             ┆ 1181  │\n",
       "│ LMS           ┆ 669   │\n",
       "└───────────────┴───────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_sub_tags(tags: str):\n",
    "    split = tags.split(sep=\" \")\n",
    "    new_tag = [x[:-1] if x[-1].isdigit() else x for x in split]\n",
    "    return \" \".join(new_tag)\n",
    "\n",
    "dataset = dataset.with_columns(\n",
    "    pl.col(\"corrected_tag\").apply(remove_sub_tags)\n",
    ")\n",
    "\n",
    "dataset[\"corrected_tag\"].str.split(by = \" \").explode().value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset[\"corrected_tag\"].str.split(by = \" \").explode().unique().sort().to_list()\n",
    "target = dict(zip(target, range(len(target))))\n",
    "reverse_target = {v : k for k, v in target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tags: str) -> list[float]:\n",
    "    \"\"\"Turn str with tags into list with digit labels.\n",
    "\n",
    "    Args:\n",
    "        tags (str): tag text representation.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: numeric labels.\n",
    "    \"\"\"\n",
    "    split = tags.split(sep = \" \")\n",
    "    res = np.zeros(len(target))\n",
    "    for x in split:\n",
    "        res[target[x]] = 1\n",
    "    return res.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.with_columns(pl.col(\"corrected_tag\").apply(vectorize).alias(\"labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (54_648, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Направление</th><th>Факультет</th><th>ID студента</th><th>Оценка</th><th>Категория</th><th>Тег</th><th>Комментарий</th><th>Статус</th><th>Neutral</th><th>Positive</th><th>Negative</th><th>Exclamations</th><th>have_code</th><th>Neutral_NLP</th><th>Positive_NLP</th><th>Negative_NLP</th><th>Speech_NLP</th><th>corrected_tag</th><th>labels</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>list[f64]</td></tr></thead><tbody><tr><td>&quot;C&quot;</td><td>113.0</td><td>1493.0</td><td>1.0</td><td>&quot;Видео&quot;</td><td>&quot;VP2&quot;</td><td>&quot;Видео лагает&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>1.00001</td><td>0.010663</td><td>0.00001</td><td>0.00001</td><td>&quot;VP&quot;</td><td>[0.0, 0.0, … 1.0]</td></tr><tr><td>&quot;C&quot;</td><td>113.0</td><td>5580.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Торгом Бабаян!…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>5</td><td>false</td><td>0.437833</td><td>0.056662</td><td>0.140346</td><td>0.051855</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&quot;E&quot;</td><td>126.0</td><td>5619.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3&quot;</td><td>&quot;Спасибо)&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.00001</td><td>0.00001</td><td>0.00001</td><td>1.00001</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>310.0</td><td>3.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H2 E1&quot;</td><td>&quot;комментарий со…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.930468</td><td>0.025189</td><td>0.119213</td><td>0.000378</td><td>&quot;H E&quot;</td><td>[1.0, 1.0, … 0.0]</td></tr><tr><td>&quot;E&quot;</td><td>123.0</td><td>1913.0</td><td>5.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H3 D&quot;</td><td>&quot;Жонибек, хочу …</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2</td><td>false</td><td>0.069552</td><td>0.217348</td><td>0.019134</td><td>0.507822</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Z&quot;</td><td>133.0</td><td>null</td><td>3.0</td><td>&quot;ДЗ&quot;</td><td>&quot;H2&quot;</td><td>&quot;требуемый форм…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.822199</td><td>0.013647</td><td>0.020974</td><td>0.00001</td><td>&quot;H&quot;</td><td>[0.0, 1.0, … 0.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>&quot;S1&quot;</td><td>&quot;заплатила и да…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.228166</td><td>0.042098</td><td>0.644235</td><td>0.006108</td><td>&quot;S&quot;</td><td>[0.0, 0.0, … 0.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>7.0</td><td>null</td><td>&quot;LMS&quot;</td><td>&quot;Крайне раздраж…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.692652</td><td>0.073706</td><td>0.262852</td><td>0.00523</td><td>&quot;LMS&quot;</td><td>[0.0, 0.0, … 0.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;VC2 VP2&quot;</td><td>&quot;Аналитик данны…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>true</td><td>0.705795</td><td>0.053413</td><td>0.320831</td><td>0.001511</td><td>&quot;VC VP&quot;</td><td>[0.0, 0.0, … 1.0]</td></tr><tr><td>&quot;Z&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;VP2 VC2&quot;</td><td>&quot;Системный анал…</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0</td><td>false</td><td>0.679189</td><td>0.092698</td><td>0.156115</td><td>0.00408</td><td>&quot;VP VC&quot;</td><td>[0.0, 0.0, … 1.0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (54_648, 19)\n",
       "┌────────────┬───────────┬────────────┬────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Направлени ┆ Факультет ┆ ID         ┆ Оценка ┆ … ┆ Negative_ ┆ Speech_NL ┆ corrected ┆ labels    │\n",
       "│ е          ┆ ---       ┆ студента   ┆ ---    ┆   ┆ NLP       ┆ P         ┆ _tag      ┆ ---       │\n",
       "│ ---        ┆ f64       ┆ ---        ┆ f64    ┆   ┆ ---       ┆ ---       ┆ ---       ┆ list[f64] │\n",
       "│ str        ┆           ┆ f64        ┆        ┆   ┆ f64       ┆ f64       ┆ str       ┆           │\n",
       "╞════════════╪═══════════╪════════════╪════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ C          ┆ 113.0     ┆ 1493.0     ┆ 1.0    ┆ … ┆ 0.00001   ┆ 0.00001   ┆ VP        ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0]      │\n",
       "│ C          ┆ 113.0     ┆ 5580.0     ┆ 5.0    ┆ … ┆ 0.140346  ┆ 0.051855  ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ E          ┆ 126.0     ┆ 5619.0     ┆ 5.0    ┆ … ┆ 0.00001   ┆ 1.00001   ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ E          ┆ 123.0     ┆ 310.0      ┆ 3.0    ┆ … ┆ 0.119213  ┆ 0.000378  ┆ H E       ┆ [1.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ E          ┆ 123.0     ┆ 1913.0     ┆ 5.0    ┆ … ┆ 0.019134  ┆ 0.507822  ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ …          ┆ …         ┆ …          ┆ …      ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ Z          ┆ 133.0     ┆ null       ┆ 3.0    ┆ … ┆ 0.020974  ┆ 0.00001   ┆ H         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ 0.0    ┆ … ┆ 0.644235  ┆ 0.006108  ┆ S         ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ 7.0    ┆ … ┆ 0.262852  ┆ 0.00523   ┆ LMS       ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ null   ┆ … ┆ 0.320831  ┆ 0.001511  ┆ VC VP     ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0]      │\n",
       "│ Z          ┆ null      ┆ null       ┆ null   ┆ … ┆ 0.156115  ┆ 0.00408   ┆ VP VC     ┆ [0.0,     │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 0.0, …    │\n",
       "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ 1.0]      │\n",
       "└────────────┴───────────┴────────────┴────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_dataset = dataset.select(\n",
    "    pl.col(\"Комментарий\"),\n",
    "    pl.col(\"Направление\"),\n",
    "    pl.col(\"Факультет\"),\n",
    "    pl.col(\"Оценка\"),\n",
    "    pl.col(\"Neutral\"),\n",
    "    pl.col(\"Positive\"),\n",
    "    pl.col(\"Negative\"),\n",
    "    pl.col(\"Exclamations\"),\n",
    "    pl.col(\"have_code\"),\n",
    "    pl.col(\"Neutral_NLP\"),\n",
    "    pl.col(\"Positive_NLP\"),\n",
    "    pl.col(\"Negative_NLP\"),\n",
    "    pl.col(\"Speech_NLP\"),\n",
    "    pl.col(\"corrected_tag\"),\n",
    "    pl.col(\"labels\"),\n",
    "    pl.col(\"corrected_tag\").str.split(by=\" \").alias(\"temp\"),\n",
    ")\n",
    "clear_dataset = clear_dataset.explode(columns=[\"temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    clear_dataset,\n",
    "    test_size=0.1,\n",
    "    random_state=3317,\n",
    "    stratify=clear_dataset[\"temp\"],\n",
    ")\n",
    "\n",
    "train_df = train_df.drop(columns=[\"corrected_tag\", \"temp\"])\n",
    "test_df = test_df.drop(columns=[\"corrected_tag\", \"temp\"])\n",
    "\n",
    "train_df = train_df.rename({\"Комментарий\": \"text\"})\n",
    "test_df = test_df.rename({\"Комментарий\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df.to_pandas(), split=\"train\")\n",
    "test_dataset = Dataset.from_pandas(test_df.to_pandas(), split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "\n",
    "\n",
    "def preprocess_data(sample: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"Encode input text into sequence of tokens.\n",
    "    Also add corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        sample (dict[str, Any]): raw input text.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: transformed sample with tokenized text and labels.\n",
    "    \"\"\"\n",
    "    text = sample[\"text\"]\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    encoding[\"labels\"] = sample[\"labels\"]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e3b5e54f4d47189b00bc2fdd12a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61118 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c2055acbfe4d6fa28b5261a72de88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6791 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train = train_dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=train_dataset.column_names\n",
    ")\n",
    "encoded_test = test_dataset.map(\n",
    "    preprocess_data, batched=True, remove_columns=test_dataset.column_names\n",
    ")\n",
    "encoded_train.set_format(\"torch\")\n",
    "encoded_test.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Training with FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, ignore_index=-100, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.CE = nn.CrossEntropyLoss(reduction='none', ignore_index=ignore_index)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        minus_logpt = self.CE(input, target)\n",
    "        pt = torch.exp(-minus_logpt) \n",
    "        focal_loss = (1-pt)**self.gamma * minus_logpt\n",
    "\n",
    "        if self.alpha != None:\n",
    "            focal_loss *= self.alpha.gather(0, target)\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            focal_loss = focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            focal_loss = focal_loss.sum()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalBert(BertForSequenceClassification):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = nn.MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = MultiLabelFocalLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = nn.BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(\n",
    "    predictions: np.ndarray, labels: np.ndarray, threshold: float = 0.5\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Compute mltilabel metrics.\n",
    "\n",
    "    Args:\n",
    "        predictions (np.ndarray): logits array\n",
    "        labels (np.ndarray): labels array\n",
    "        threshold (float, optional): activation threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: metrics dict\n",
    "    \"\"\"\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    f1_micro_average = f1_score(y_true=labels, y_pred=y_pred, average=\"micro\")\n",
    "    roc_auc = roc_auc_score(labels, y_pred, average=\"micro\")\n",
    "    accuracy = accuracy_score(labels, y_pred)\n",
    "    metrics = {\"f1\": f1_micro_average, \"roc_auc\": roc_auc, \"accuracy\": accuracy}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction) -> dict[str, float]:\n",
    "    \"\"\"Metrics computation wrapper.\n",
    "\n",
    "    Args:\n",
    "        p (EvalPrediction): hf model output\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: metrics dict\n",
    "    \"\"\"\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(predictions=preds, labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_pipeline(\n",
    "    exp_name: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    train_dataset: Dataset,\n",
    "    eval_dataset: Dataset,\n",
    "    batch_size: int = 64,\n",
    "    lr: float = 2e-5,\n",
    "    epochs_num: int = 20,\n",
    "    model_name=None\n",
    ") -> Trainer:\n",
    "    \"\"\"Training process wrapper.\n",
    "\n",
    "    Args:\n",
    "        exp_name (str): name of the local folder\n",
    "        for saving model checkpoints.\n",
    "        tokenizer (AutoTokenizer): model tokenizer\n",
    "        train_dataset (Dataset): train dataset split\n",
    "        eval_dataset (Dataset): test dataset split\n",
    "        batch_size (int, optional): number of samples\n",
    "        in sigle batch. Defaults to 32.\n",
    "        lr (float, optional): model's learning rate. Defaults to 2e-5.\n",
    "        epochs_num (int, optional):\n",
    "        number of training iterations. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        Trainer: hf training pipeline abstraction class.\n",
    "    \"\"\"\n",
    "    args = TrainingArguments(\n",
    "        exp_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs_num,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    model = FocalBert.from_pretrained(\n",
    "        \"cointegrated/rubert-tiny2\",\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        num_labels=len(target),\n",
    "        id2label=target,\n",
    "        label2id=reverse_target\n",
    "    )\n",
    "    if model_name is not None:\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 180\n",
    "EPOCHS = 75\n",
    "LR = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FocalBert were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = make_training_pipeline(\"f_focal\", tokenizer, encoded_train, encoded_test, batch_size=BATCH_SIZE, epochs_num=EPOCHS, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='762' max='12750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  762/12750 06:54 < 1:49:04, 1.83 it/s, Epoch 4.48/75]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340161</td>\n",
       "      <td>0.636617</td>\n",
       "      <td>0.749821</td>\n",
       "      <td>0.462229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273522</td>\n",
       "      <td>0.740604</td>\n",
       "      <td>0.823965</td>\n",
       "      <td>0.544692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.348400</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>0.777118</td>\n",
       "      <td>0.853319</td>\n",
       "      <td>0.580769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.348400</td>\n",
       "      <td>0.220424</td>\n",
       "      <td>0.793016</td>\n",
       "      <td>0.863309</td>\n",
       "      <td>0.601826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.15058404207229614,\n",
       " 'eval_f1': 0.8803578859758635,\n",
       " 'eval_roc_auc': 0.9268149647197956,\n",
       " 'eval_accuracy': 0.768811662494478,\n",
       " 'eval_runtime': 8.3648,\n",
       " 'eval_samples_per_second': 811.851,\n",
       " 'eval_steps_per_second': 6.456,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = trainer.predict(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8803578859758635, 'roc_auc': 0.9268149647197956, 'accuracy': 0.768811662494478}\n"
     ]
    }
   ],
   "source": [
    "print(compute_metrics(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = make_training_pipeline(\"v\", tokenizer, encoded_train, encoded_test, batch_size=BATCH_SIZE, epochs_num=EPOCHS, lr=LR, model_name=\"f/checkpoint-4590/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_preds = trainer.predict(encoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = trainer.predict(encoded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделать сравнение с Focal Loss и без него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'Направление', 'Факультет', 'Оценка', 'Neutral', 'Positive', 'Negative', 'Exclamations', 'have_code', 'Neutral_NLP', 'Positive_NLP', 'Negative_NLP', 'Speech_NLP', 'labels'],\n",
       "    num_rows: 61118\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = pd.get_dummies(train_df.to_pandas()[\"Направление\"])\n",
    "departments = pd.get_dummies(train_df.to_pandas()[\"Факультет\"])\n",
    "meta_dataset_train = train_df.select(pl.exclude(\"Направление\", \"Факультет\")).to_pandas()\n",
    "meta_dataset_train = pd.concat([meta_dataset_train, directions, departments, pd.DataFrame(train_preds.predictions)], axis=1)\n",
    "meta_dataset_train = meta_dataset_train.drop(columns=[\"text\"])\n",
    "\n",
    "meta_dataset_test = test_df.select(pl.exclude(\"Направление\", \"Факультет\")).to_pandas()\n",
    "meta_dataset_test = pd.concat([meta_dataset_test, directions, departments, pd.DataFrame(test_preds.predictions)], axis=1)\n",
    "meta_dataset_test = meta_dataset_test.drop(columns=[\"text\"])\n",
    "\n",
    "meta_dataset_test = meta_dataset_test.dropna(subset=[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_train[[f\"label{i}\" for i in range(7)]] = np.array([el for el in meta_dataset_train[\"labels\"].to_numpy()])\n",
    "meta_dataset_test[[f\"label{i}\" for i in range(7)]] = np.array([el for el in meta_dataset_test[\"labels\"].to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_train = meta_dataset_train.drop(columns=[\"labels\"])\n",
    "meta_dataset_test = meta_dataset_test.drop(columns=[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"agModels-predictClass\"\n",
    "labels = [f\"label{i}\" for i in range(7)]\n",
    "problem_types = [f\"binary\" for i in range(7)]\n",
    "eval_metrics = [f\"roc_auc\" for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictClassPredictor_label0\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: agModels-predictClassPredictor_label0/ds_sub_fit/sub_fit_ho.\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"agModels-predictClassPredictor_label0/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #112-Ubuntu SMP Tue Mar 5 16:50:32 UTC 2024\n",
      "CPU Count:          64\n",
      "Memory Avail:       103.74 GB / 125.73 GB (82.5%)\n",
      "Disk Space Avail:   28.74 GB / 97.87 GB (29.4%)\n",
      "===================================================\n",
      "Train Data Rows:    54327\n",
      "Train Data Columns: 82\n",
      "Label Column:       label0\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    106230.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.60 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: label0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\tNote: Converting 65 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['U']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 19): ['H', 'M', 'N', 'Q', 'S', 'T', 'V', 'W', 'X', '100.0', '109.0', '112.0', '113.0', '114.0', '115.0', '125.0', '127.0', '129.0', '132.0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('bool', []) : 19 | ['H', 'M', 'N', 'Q', 'S', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 46 | ['have_code', 'B', 'C', 'D', 'E', ...]\n",
      "\t\t('float', []) : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])   :  1 | ['Exclamations']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['Оценка', 'Neutral', 'Positive', 'Negative', 'Neutral_NLP', ...]\n",
      "\t\t('int', [])       :  1 | ['Exclamations']\n",
      "\t\t('int', ['bool']) : 46 | ['have_code', 'B', 'C', 'D', 'E', ...]\n",
      "\t0.8s = Fit runtime\n",
      "\t62 features in original data used to generate 62 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.56 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.82s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 599.31s of the 899.18s of remaining time.\n",
      "\t0.942\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 598.74s of the 898.61s of remaining time.\n",
      "\t0.9534\t = Validation score   (roc_auc)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 598.25s of the 898.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9824\t = Validation score   (roc_auc)\n",
      "\t11.83s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 582.27s of the 882.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.06%)\n",
      "\t0.9838\t = Validation score   (roc_auc)\n",
      "\t5.05s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 575.85s of the 875.72s of remaining time.\n",
      "\t0.9865\t = Validation score   (roc_auc)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 573.43s of the 873.31s of remaining time.\n",
      "\t0.9867\t = Validation score   (roc_auc)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 571.24s of the 871.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.07%)\n",
      "\t0.9831\t = Validation score   (roc_auc)\n",
      "\t58.64s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 511.32s of the 811.19s of remaining time.\n",
      "\t0.9857\t = Validation score   (roc_auc)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 508.69s of the 808.56s of remaining time.\n",
      "\t0.9847\t = Validation score   (roc_auc)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 505.93s of the 805.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.08%)\n",
      "\t0.9707\t = Validation score   (roc_auc)\n",
      "\t40.09s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 464.38s of the 764.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.09%)\n",
      "\t0.9833\t = Validation score   (roc_auc)\n",
      "\t7.56s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 455.47s of the 755.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=8, gpus=0, memory=0.05%)\n"
     ]
    }
   ],
   "source": [
    "predictor = MultilabelPredictor(labels=labels, problem_types=problem_types, eval_metrics=eval_metrics, path=save_path).fit(meta_dataset_train, presets='best_quality')\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=10, criterion=\"gini\", n_estimators=150, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=150)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=train_df.loc[:, train_df.columns != 'Категория'], y=train_df[\"Категория\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict(X=test_df.loc[:, train_df.columns != 'Категория'])\n",
    "gt_labels = test_df[\"Категория\"].values\n",
    "pred_labels = [id2label[x] for x in pred_labels]\n",
    "gt_labels = [id2label[x] for x in gt_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score      support\n",
      "Видео          0.938500  0.865975  0.900780  4335.000000\n",
      "ДЗ             0.962364  0.918466  0.939903  4538.000000\n",
      "Лонгрид        0.265690  0.622549  0.372434   408.000000\n",
      "Тест           0.824786  0.804167  0.814346   240.000000\n",
      "accuracy       0.879004  0.879004  0.879004     0.879004\n",
      "macro avg      0.747835  0.802789  0.756866  9521.000000\n",
      "weighted avg   0.918176  0.879004  0.894607  9521.000000\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(gt_labels, pred_labels, output_dict=True)\n",
    "cr = pd.DataFrame(cr).T\n",
    "print(cr)\n",
    "\n",
    "cm = confusion_matrix(gt_labels, pred_labels, labels=list(label2id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "reversescale": false,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "Видео",
          "ДЗ",
          "Лонгрид",
          "Тест"
         ],
         "y": [
          "Тест",
          "Лонгрид",
          "ДЗ",
          "Видео"
         ],
         "z": [
          [
           15,
           5,
           27,
           193
          ],
          [
           97,
           29,
           254,
           28
          ],
          [
           134,
           4168,
           228,
           8
          ],
          [
           3754,
           129,
           447,
           5
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "15",
          "x": "Видео",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "5",
          "x": "ДЗ",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "27",
          "x": "Лонгрид",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "193",
          "x": "Тест",
          "xref": "x",
          "y": "Тест",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "97",
          "x": "Видео",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "29",
          "x": "ДЗ",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "254",
          "x": "Лонгрид",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "28",
          "x": "Тест",
          "xref": "x",
          "y": "Лонгрид",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "134",
          "x": "Видео",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "4168",
          "x": "ДЗ",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "228",
          "x": "Лонгрид",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "8",
          "x": "Тест",
          "xref": "x",
          "y": "ДЗ",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "3754",
          "x": "Видео",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "129",
          "x": "ДЗ",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "447",
          "x": "Лонгрид",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "5",
          "x": "Тест",
          "xref": "x",
          "y": "Видео",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "Predicted value",
          "x": 0.5,
          "xref": "paper",
          "y": -0.15,
          "yref": "paper"
         },
         {
          "showarrow": false,
          "text": "Real value",
          "textangle": -90,
          "x": -0.16,
          "xref": "paper",
          "y": 0.5,
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion matrix"
        },
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": ""
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  "
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "x = list(label2id.keys())\n",
    "y = list(reversed(label2id.keys()))\n",
    "fig = ff.create_annotated_heatmap(np.flipud(cm), x=x, y=y, colorscale=\"Viridis\")\n",
    "fig.update_layout(title_text=\"Confusion matrix\")\n",
    "fig.add_annotation(\n",
    "    dict(\n",
    "        x=0.5,\n",
    "        y=-0.15,\n",
    "        showarrow=False,\n",
    "        text=\"Predicted value\",\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    dict(\n",
    "        x=-0.16,\n",
    "        y=0.5,\n",
    "        showarrow=False,\n",
    "        text=\"Real value\",\n",
    "        textangle=-90,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig[\"data\"][0][\"showscale\"] = True\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2307\n",
       "                \n",
       "                    &plusmn; 0.2420\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.05%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1977\n",
       "                \n",
       "                    &plusmn; 0.2157\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 82.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1900\n",
       "                \n",
       "                    &plusmn; 0.2752\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1808\n",
       "                \n",
       "                    &plusmn; 0.2737\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0364\n",
       "                \n",
       "                    &plusmn; 0.0942\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Speech_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0330\n",
       "                \n",
       "                    &plusmn; 0.0774\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Оценка\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0312\n",
       "                \n",
       "                    &plusmn; 0.0638\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Neutral_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0236\n",
       "                \n",
       "                    &plusmn; 0.0336\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Positive_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0202\n",
       "                \n",
       "                    &plusmn; 0.0415\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Negative_NLP\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.99%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0087\n",
       "                \n",
       "                    &plusmn; 0.0238\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Exclamations\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0090\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Z\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "                    &plusmn; 0.0111\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                F\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0058\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                122.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0027\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                116.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0059\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Y\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0078\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Positive\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                103.0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0035\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                R\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Negative\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                L\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.39%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 50 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"RandomForestClassifier(class_weight='balanced', max_depth=10, n_estimators=150)\", description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='3', weight=0.2307170893956611, std=0.1210054330856475, value=None), FeatureWeight(feature='0', weight=0.19774163103797826, std=0.10784942862928834, value=None), FeatureWeight(feature='1', weight=0.1900068565058053, std=0.13761824626795846, value=None), FeatureWeight(feature='2', weight=0.18077571595339764, std=0.13683658306610924, value=None), FeatureWeight(feature='Speech_NLP', weight=0.03643594020109274, std=0.047121069515174356, value=None), FeatureWeight(feature='Оценка', weight=0.03301745465035411, std=0.038677750916137295, value=None), FeatureWeight(feature='Neutral_NLP', weight=0.031219837342808025, std=0.03191723325745654, value=None), FeatureWeight(feature='Positive_NLP', weight=0.02362133819180187, std=0.016818812829129105, value=None), FeatureWeight(feature='Negative_NLP', weight=0.020206729353502494, std=0.02076402643141657, value=None), FeatureWeight(feature='Exclamations', weight=0.008656752166771944, std=0.01192172522835438, value=None), FeatureWeight(feature='Z', weight=0.0051492467913618195, std=0.004479782686568709, value=None), FeatureWeight(feature='F', weight=0.003843163354909346, std=0.005548738763783975, value=None), FeatureWeight(feature='122.0', weight=0.003208294438790977, std=0.0028989802203973586, value=None), FeatureWeight(feature='116.0', weight=0.002655952963172194, std=0.002632732121058257, value=None), FeatureWeight(feature='Y', weight=0.002641578596777077, std=0.002932957812592763, value=None), FeatureWeight(feature='Positive', weight=0.0020942764710965545, std=0.003896218220718816, value=None), FeatureWeight(feature='103.0', weight=0.002088955796174922, std=0.0014967015905626095, value=None), FeatureWeight(feature='R', weight=0.0019401956497559316, std=0.0017669000828721899, value=None), FeatureWeight(feature='Negative', weight=0.0018340849092393118, std=0.0033603694056714567, value=None), FeatureWeight(feature='L', weight=0.0015629090251714256, std=0.0020533570389643092, value=None)], remaining=50), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.explain_weights(model, target_names=id2label, feature_names=train_df.loc[:, train_df.columns != 'Категория'].columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
