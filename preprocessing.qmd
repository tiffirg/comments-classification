# –û—Ç—á–µ—Ç –ø–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥—É –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö


```{python}
import re
import nltk
import emoji
import emosent
import pandas as pd
import numpy as np
import warnings
import seaborn as sns
from nltk.corpus import stopwords
from string import punctuation as PUNCT
```

–°—Ç–æ–∏—Ç —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è TF-IDF –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ –º–æ–¥–µ–ª—å:
```{python}
warnings.filterwarnings("ignore")
nltk.download("stopwords")
RUSSIAN_STOPWORDS = set(stopwords.words("russian"))
```

## –î–∞—Ç–∞—Å–µ—Ç

```{python}
dataset = pd.read_csv("practice_cleaned.csv")
dataset.head()
```

–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω—ã–Ω–µ—à–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ:

```{python}
dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].unique()
```

```{python}
dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].value_counts()
```

```{python}
dataset[(dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].str.contains("–∫—É—Ä–∞—Ç–æ—Ä") | dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].str.contains("–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫"))]["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].value_counts()
```
–í—ã–≤–æ–¥: –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '–ö–∞—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤', '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º', '–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã' –ª—É—á—à–µ –æ—Ç–±—Ä–æ—Å–∏—Ç—å, —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ö–∞—Ç–µ–≥–æ—Ä–∏—è '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º' –ø–æ —Å–º—ã—Å–ª–æ–≤–æ–º—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç—Å—è —Å–æ –≤—Å–µ–º–∏ –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏, –ø–æ—ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å—Ç–æ–∏—Ç –ø–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ–¥ —Å–æ–º–Ω–µ–Ω–∏–µ.

```{python}
dataset = dataset[~dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].isin(['–ö–∞—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
                                              '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º',
                                              '–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã'])]
```

–î–ª—è –±—É–¥—É—â–µ–≥–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ —É—á—Ç–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å—Å—ã–ª–æ–∫:
```{python}
dataset[dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].str.contains("–°–°–´–õ–ö–ê")]["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].value_counts()
``` 

## –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥

–ü–æ—Å–ª–µ –∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Ç–∞–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã, –∫–∞–∫: \
 ‚Ä¢ –í–º–µ—Å—Ç–æ —Å—Å—ã–ª–æ–∫ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö —É–∫–∞–∑–∞–Ω–æ "–°–°–´–õ–ö–ê". –ë—ã–ª–æ —Ä–µ—à–µ–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º —Ä–µ–≥–∏—Å—Ç—Ä–æ–º, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞—Ç—å –¥–ª—è –±—É–¥—É—â–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä NER. –ü–æ –ª–æ–≥–∏–∫–µ —Å—Å—ã–ª–∫–∏ —á–∞—â–µ –≤—Å–µ–≥–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö. \
 ‚Ä¢ –í –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö —á–∞—Å—Ç–æ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è —ç–º–æ–¥–∑–∏, –ø—Ä–∏—á–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∏–¥–æ–≤. –≠—Ç–æ –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, ":)", —ç—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–µ —ç–º–æ–¥–∑–∏, –∫ –ø—Ä–∏–º–µ—Ä—É, "üòä", –∞ —Ç–∞–∫–∂–µ –ø–æ–¥–æ–±–Ω—ã–µ —ç—Ç–∏–º "‚ô•". –í–æ-–ø–µ—Ä–≤—ã—Ö –æ–Ω–∏ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—É—é—Ç—Å—è –¥–ª—è LLM, –≤–æ-–≤—Ç–æ—Ä—ã—Ö –∏–∑ –Ω–∏—Ö –∏–∑—ã–º–∞–µ—Ç—Å—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞. \
 ‚Ä¢ –¢–∞–∫–∂–µ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ —Ä–µ–¥–∫–æ –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è - —ç—Ç–æ —Ç–æ–∂–µ –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–π –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ –µ—â–µ –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫.
 ‚Ä¢ –í –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –∏–Ω–æ–≥–¥–∞ –ø–æ–ø–∞–¥–∞—é—Ç—Å—è –∫—É—Å–∫–∏ –∫–æ–¥–∞, –Ω–µ —Ä–µ–¥–∫–æ –≤–∏–¥–Ω—ã –æ—à–∏–±–∫–∏. –¢–∞–∫ –∂–µ –ø–æ–ø–∞–¥–∞—é—Ç—Å—è —Å—Å—ã–ª–∫–∏ –Ω–∞ Telegram –∏ –¥—Ä—É–≥–∏–µ —Å–æ—Ü.—Å–µ—Ç–∏. –ü–æ —ç—Ç–∏–º –ø—Ä–∏—á–∏–Ω–∞–º —Ñ–∏–ª—å—Ç—Ä—É—é—Ç—Å—è –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ç–µ–≥–∏, –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏, –∫–∞–∫ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ, —Ç–∞–∫ –∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ. \
 ‚Ä¢ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –≤—ã–¥–µ–ª—è—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ª–æ–≤–∞ –∫–∞–≤—ã—á–∫–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ –∏—Ç–æ–≥—É –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–≤—ã—á–µ–∫ –ø–æ–¥—Ä—è–¥ (2 –∏ –±–æ–ª–µ–µ), –ø–æ—ç—Ç–æ–º—É –≤—Å—ë –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É –æ–¥–Ω–æ–π –∫–∞–≤—ã—á–∫–∏. 

```{python}
test_smiles = [":\)", ":\^\)", ":\(", "=\)", ":o\)",
               ":D", "=D", ":-/", ":/", ":P", "=]",
               ":-—Ä", "8\)", "=O", ":-o", "X-\)",
               "\^_\^", "o_O", "\$_\$", "\^o\^",
               "\^3\^", "\*-\*", "<3", "\^3", ":\^\)"]

def preprocessing_text(text: str) -> list[str, float, float, float, int]:
  neutral, positive, negative = 0, 0, 0
  emojis = emosent.get_emoji_sentiment_rank_multiple(text)
  amount_emojis = len(emojis)
  if amount_emojis:
    for emoji_symbol in emojis:
      emoji_rank = emoji_symbol["emoji_sentiment_rank"]
      positive += emoji_rank["positive"]
      neutral += emoji_rank["neutral"]
      negative += emoji_rank["negative"]
    neutral, positive, negative = neutral / amount_emojis, positive / amount_emojis, negative / amount_emojis
  text = emoji.replace_emoji(text, replace=' ')
  text = re.sub(fr"{'|'.join(test_smiles)}", ' ', text)
  text = re.sub(r'@[_A-Za-z0-9/\\-]+', ' ', text)
  text = re.sub(r'C:\\{1,2}\S+\.\S+', ' ', text)
  text = re.sub(r'[~_A-Za-z0-9-]+/[~_A-Za-z0-9-/.]+\.[~_A-Za-z0-9-\.]+', ' ', text)
  text = re.sub(r'/[~_A-Za-z0-9-]+/[~_A-Za-z0-9-/][,:]?', ' ', text)
  text = re.sub(r'\([^\S\n]*\)', ' ', text)
  text = re.sub(r'"{2,4}', '"', text)
  text = re.sub("[^\S\n]+", " ", text)
  text = re.sub("–°–°–´–õ–ö–ê", '', text)
  text = text.strip()
  amount_exclamations = 0
  for symbol in text:
    if symbol == "!":
      amount_exclamations += 1
  return text, neutral, positive, negative, amount_exclamations

```

–î–æ–±–∞–≤–∏–º –≤ –¥–∞—Ç–∞—Å–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–∑–∏—Ç–∏–≤–∞, –Ω–µ–≥–∞—Ç–∏–≤–∞, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –∞ —Ç–∞–∫–∂–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è:
```{python}
dataset[["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "Neutral", "Positive", "Negative", "Exclamations"]] = dataset.apply(lambda x: preprocessing_text(x["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]), axis=1, result_type="expand")
```

## –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è

–í –¥–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ –≤–∏–¥–µ–Ω —Å–º—ã—Å–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Downsampling –ø–æ –ø—Ä–∏—á–∏–Ω–µ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤, Upsampling –∑–¥–µ—Å—å –∫—É–¥–∞ –±–æ–ª–µ–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ–Ω. –ù–æ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –µ–≥–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞, –æ–¥–∏–Ω —Ñ–∞–∫—Ç —Å—Ç–∞–≤–∏—Ç —ç—Ç–æ –ø–æ–¥ —Å–æ–º–Ω–µ–Ω–∏–µ - 2 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑–º–µ—Ä—è—é—Ç—Å—è —Ç—ã—Å—è—á–∞–º–∏, –¥—Ä—É–≥–∏–µ 2 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–µ—Å—è—Ç–∫–∞–º–∏ —Ç—ã—Å—è—á. \\
–ì–æ–≤–æ—Ä—è –æ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, —Ç–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ —Ö–æ—Ç–∏–º –ø—Ä–∏–≤–µ—Å—Ç–∏ –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫ 23 000 —Å–µ–º–ø–ª–∞–º, –∫–∞–∫ —É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "–î–ó", –¥–ª—è —ç—Ç–æ–≥–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–ª–∏—Å—å –¥–≤–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: \
 ‚Ä¢ [–ü–∞—Ä–∞—Ñ—Ä–∞–∑–µ—Ä, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –Ω–∞ –±–∞–∑–µ ruT5](https://huggingface.co/cointegrated/rut5-base-paraphraser). –ü–æ–¥–æ–±–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–∑–∞–ª–æ—Å—å —Ö–æ—Ä–æ—à–∏–º, –æ–¥–Ω–∞–∫–æ –ø–æ –∏—Ç–æ–≥—É –±—ã–ª –≤–∏–¥–µ–Ω –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö (–±–æ–ª–µ–µ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π), –∞ —Ç–∞–∫–∂–µ –Ω–∏–∑–∫—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. \
 ‚Ä¢ ruGPT3-medium —Å —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–æ–º –Ω–∞ 4000 —Å–µ–º–ø–ª–∞—Ö. –í–∏–∑—É–∞–ª—å–Ω–æ –∫–∞–∂–µ—Ç—Å—è —Ö–æ—Ä–æ—à–∏–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –¥–ª –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–¥–Ω–∞–∫–æ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ—Å—è—Ç–∫–æ–≤ —Ç—ã—Å—è—á –Ω–∞ –æ–¥–Ω—É –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –≤—Å—ë —Ä–∞–≤–Ω–æ –ø—Ä–∏—Ö–æ–¥–∏–º –∫ –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤. –í —ç—Ç–æ–º —Ä–µ—à–µ–Ω–∏–∏ –≤–∏–∂—É –¥—Ä—É–≥—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É - —É—Ä–∞–≤–Ω—è—Ç—å –∫–ª–∞—Å—Å—ã "–î–ó" –∏ "–í–∏–¥–µ–æ", –∞ "–õ–æ–Ω–≥—Ä–∏–¥" —Å "–¢–µ—Å—Ç" –¥–æ 3-4 —Ç—ã—Å—è—á. –ê –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å FocalLoss –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∑–±–∞–ª–∞–Ω—Å–∞.

### ruGPT3-medium –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö

–î–ª—è –Ω–∞—á–∞–ª–∞ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –≤—ã—Å—Ç–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
```{python}
lengths = [len(el) for el in dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]]
pd.Series(lengths).describe()
```

```{python}
sns.displot(lengths, bins=100)
```

–¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º —Ç—É –∂–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∫–ª–∞—Å—Å–∞–º.
–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–î–ó":
```{python}
sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–î–ó"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–í–∏–¥–µ–æ":
```{python}
sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–í–∏–¥–µ–æ"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–¢–µ—Å—Ç":
```{python}
sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–¢–µ—Å—Ç"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–õ–æ–Ω–≥—Ä–∏–¥":
```{python}
sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–õ–æ–Ω–≥—Ä–∏–¥"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ò—Å—Ö–æ–¥—è –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, –º–æ–∂–Ω–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É 512 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –î–ª—è –æ–±—É—á–µ–Ω–∏—è ruGPT3 –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —Å–ø–µ—Ü. —Ç–æ–∫–µ–Ω–æ–≤:
```{python}
def convert(unit):
    category, text = unit["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"], unit["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]
    if category == "–î–ó":
        category = "–î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ"
    elif category == "–õ–æ–Ω–≥—Ä–∏–¥":
        category = "–û–±–∑–æ—Ä, –ª–æ–Ω–≥—Ä–∏–¥, long read"
    text = re.sub(r'\s+', ' ', text)
    text = f"<s>–¢–µ–º–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ Skillbox: {category}\n{text}</s>"
    return text
```
–ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ruGPT3:
```{python}
aug_data = dataset[(dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].isin(['–í–∏–¥–µ–æ', '–î–ó', '–õ–æ–Ω–≥—Ä–∏–¥', '–¢–µ—Å—Ç'])) & (dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].notna())]
train = aug_data.groupby('–ö–∞—Ç–µ–≥–æ—Ä–∏—è', group_keys=False).apply(lambda x: x.sample(1000))
train = train.sample(frac=1)
train_data = list(train[["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]].apply(convert, axis=1))
with open("train.txt", "w", encoding="utf-8") as file:
    file.write("\n".join(train_data))
```

–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è [—Ñ–∞–π–ª–æ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è gpt](https://raw.githubusercontent.com/buvanenko/finetune_rugpt3/main/pretrain_transformers.py), –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –°–±–µ—Ä–æ–º:
```{console}
python pretrain_transformers.py \
    --output_dir=essays_model \
    --model_type=gpt2 \
    --model_name_or_path=sberbank-ai/rugpt3medium_based_on_gpt2 \
    --do_train \
    --train_data_file=train.txt \
    --fp16 \
    --per_gpu_train_batch_size 1 \
    --gradient_accumulation_steps 1 \
    --num_train_epochs 5 \
    --block_size 2048 \
    --overwrite_output_dir
```

## –í—ã–≤–æ–¥—ã

1. –î–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã, –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ—á–Ω–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞ —ç–º–±–µ–¥–∏–Ω–≥–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–ª–æ–≤. –°—Ç–æ–∏—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –∏–º–µ–Ω–∞, –æ–±—Ä–∞—â–µ–Ω–∏—è, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞. 
2. –£ –¥–∞–Ω–Ω—ã—Ö –æ–≥—Ä–æ–º–Ω—ã–π –¥–∏–∑–±–∞–ª–∞–Ω—Å –∏–∑-–∑–∞ –∫–æ—Ç–æ—Ä–æ–≥–æ downsampling –∏ upsampling —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø—Ä–∏–≤–µ–¥—É—Ç –∫ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É. –û–¥–Ω–∞–∫–æ —Å—Ä–∞–∑—É –æ—á–µ–≤–∏–¥–Ω–æ, —á—Ç–æ —Å—Ç–æ–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∑–±–∞–ª–∞–Ω—Å–∞, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∏ FocalLoss.
3. –°—Ç–æ–∏—Ç —É–±—Ä–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '–ö–∞—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤', '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º', '–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã' –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
4. –ò–∑ —ç–º–æ–¥–∑–∏ –∏ –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–π –≤–∑—è—Ç–∞ —Ö–æ—Ä–æ—à–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞. –≠—Ç–æ —É–∂–µ 4 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞, –≤–ø–æ–ª–Ω–µ –≤–æ–∑–º–æ–∂–Ω–æ –≤–∑—è—Ç—å –µ—â–µ –æ–¥–∏–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ bert deeppalov.