# –û—Ç—á–µ—Ç –ø–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥—É –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö


```{python}
import re
import nltk
import emoji
import emosent
import pandas as pd
import numpy as np
import warnings
import seaborn as sns
from nltk.corpus import stopwords
from string import punctuation as PUNCT
from dostoevsky.tokenization import RegexTokenizer
from dostoevsky.models import FastTextSocialNetworkModel
from polyglot.detect import Detector
from polyglot.detect.base import logger as polyglot_logger
```

–°—Ç–æ–∏—Ç —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è TF-IDF –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ –º–æ–¥–µ–ª—å:
```{python}
warnings.filterwarnings("ignore")
polyglot_logger.setLevel("ERROR")
nltk.download("stopwords")
RUSSIAN_STOPWORDS = set(stopwords.words("russian"))
```

```{python}
sentiment_tokenizer = RegexTokenizer()
sentiment_model = FastTextSocialNetworkModel(tokenizer=sentiment_tokenizer)
```

## –î–∞—Ç–∞—Å–µ—Ç

```{python}
dataset = pd.read_csv("practice_cleaned.csv")
dataset.head()
```

–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω—ã–Ω–µ—à–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ:

```{python}
dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].unique()
```

```{python}
dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].value_counts()
```

```{python}
categories = ['–í–∏–¥–µ–æ', '–î–ó', '–õ–æ–Ω–≥—Ä–∏–¥', '–¢–µ—Å—Ç']
```

```{python}
dataset[(dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].str.contains("–∫—É—Ä–∞—Ç–æ—Ä") | dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].str.contains("–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫"))]["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].value_counts()
```
–í—ã–≤–æ–¥: –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '–ö–∞—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤', '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º', '–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã' –ª—É—á—à–µ –æ—Ç–±—Ä–æ—Å–∏—Ç—å, —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ö–∞—Ç–µ–≥–æ—Ä–∏—è '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º' –ø–æ —Å–º—ã—Å–ª–æ–≤–æ–º—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç—Å—è —Å–æ –≤—Å–µ–º–∏ –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏, –ø–æ—ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å—Ç–æ–∏—Ç –ø–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ–¥ —Å–æ–º–Ω–µ–Ω–∏–µ.

<!-- ```{python}
dataset = dataset[~dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].isin(['–ö–∞—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
                                              '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º',
                                              '–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã'])]
``` -->

–î–ª—è –±—É–¥—É—â–µ–≥–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ —É—á—Ç–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Å—Å—ã–ª–æ–∫:
```{python}
dataset[dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].str.contains("–°–°–´–õ–ö–ê")]["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].value_counts()
``` 

## –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥

–ü–æ—Å–ª–µ –∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Ç–∞–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã, –∫–∞–∫: \
 ‚Ä¢ –í–º–µ—Å—Ç–æ —Å—Å—ã–ª–æ–∫ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö —É–∫–∞–∑–∞–Ω–æ "–°–°–´–õ–ö–ê". –ë—ã–ª–æ —Ä–µ—à–µ–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º —Ä–µ–≥–∏—Å—Ç—Ä–æ–º, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞—Ç—å –¥–ª—è –±—É–¥—É—â–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä NER. –ü–æ –ª–æ–≥–∏–∫–µ —Å—Å—ã–ª–∫–∏ —á–∞—â–µ –≤—Å–µ–≥–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "–í–∏–¥–µ–æ". \
 ‚Ä¢ –í –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö —á–∞—Å—Ç–æ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è —ç–º–æ–¥–∑–∏, –ø—Ä–∏—á–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∏–¥–æ–≤. –≠—Ç–æ –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, ":)", —ç—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–µ —ç–º–æ–¥–∑–∏, –∫ –ø—Ä–∏–º–µ—Ä—É, "üòä", –∞ —Ç–∞–∫–∂–µ –ø–æ–¥–æ–±–Ω—ã–µ —ç—Ç–∏–º "‚ô•". –í–æ-–ø–µ—Ä–≤—ã—Ö –æ–Ω–∏ –≤—Å–µ —Ñ–∏–ª—å—Ç—Ä—É—é—Ç—Å—è –¥–ª—è LLM, –≤–æ-–≤—Ç–æ—Ä—ã—Ö –∏–∑ –Ω–∏—Ö –∏–∑—ã–º–∞–µ—Ç—Å—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞. \
 ‚Ä¢ –¢–∞–∫–∂–µ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ —Ä–µ–¥–∫–æ –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è - —ç—Ç–æ —Ç–æ–∂–µ –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–π –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ –µ—â–µ –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫.
 ‚Ä¢ –í –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –∏–Ω–æ–≥–¥–∞ –ø–æ–ø–∞–¥–∞—é—Ç—Å—è –∫—É—Å–∫–∏ –∫–æ–¥–∞, –Ω–µ —Ä–µ–¥–∫–æ –≤–∏–¥–Ω—ã –æ—à–∏–±–∫–∏. –¢–∞–∫ –∂–µ –ø–æ–ø–∞–¥–∞—é—Ç—Å—è —Å—Å—ã–ª–∫–∏ –Ω–∞ Telegram –∏ –¥—Ä—É–≥–∏–µ —Å–æ—Ü.—Å–µ—Ç–∏. –ü–æ —ç—Ç–∏–º –ø—Ä–∏—á–∏–Ω–∞–º —Ñ–∏–ª—å—Ç—Ä—É—é—Ç—Å—è –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ç–µ–≥–∏, –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏, –∫–∞–∫ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ, —Ç–∞–∫ –∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ. \
 ‚Ä¢ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –≤—ã–¥–µ–ª—è—é—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ª–æ–≤–∞ –∫–∞–≤—ã—á–∫–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ –∏—Ç–æ–≥—É –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–≤—ã—á–µ–∫ –ø–æ–¥—Ä—è–¥ (2 –∏ –±–æ–ª–µ–µ), –ø–æ—ç—Ç–æ–º—É –≤—Å—ë –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É –æ–¥–Ω–æ–π –∫–∞–≤—ã—á–∫–∏. 

```{python}
test_smiles = [":\)", ":\^\)", ":\(", "=\)", ":o\)",
               ":D", "=D", ":-/", ":/", ":P", "=]",
               ":-—Ä", "8\)", "=O", ":-o", "X-\)",
               "\^_\^", "o_O", "\$_\$", "\^o\^",
               "\^3\^", "\*-\*", "<3", "\^3", ":\^\)"]

def preprocessing_text(text):
  neutral, positive, negative = 0, 0, 0
  emojis = emosent.get_emoji_sentiment_rank_multiple(text)
  amount_emojis = len(emojis)
  if amount_emojis:
    for emoji_symbol in emojis:
      emoji_rank = emoji_symbol["emoji_sentiment_rank"]
      positive += emoji_rank["positive"]
      neutral += emoji_rank["neutral"]
      negative += emoji_rank["negative"]
    neutral, positive, negative = neutral / amount_emojis, positive / amount_emojis, negative / amount_emojis
  text = emoji.replace_emoji(text, replace=' ')
  text = re.sub(fr"{'|'.join(test_smiles)}", ' ', text)
  text = re.sub(r'@[_A-Za-z0-9/\\-]+', ' ', text)
  text = re.sub(r'C:\\{1,2}\S+\.\S+', ' ', text)
  text = re.sub(r'[~_A-Za-z0-9-]+/[~_A-Za-z0-9-/.]+\.[~_A-Za-z0-9-\.]+', ' ', text)
  text = re.sub(r'/[~_A-Za-z0-9-]+/[~_A-Za-z0-9-/][,:]?', ' ', text)
  text = re.sub(r'\([^\S\n]*\)', ' ', text)
  text = re.sub(r'"{2,4}', '"', text)
  text = re.sub("[^\S\n]+", " ", text)
  text = re.sub("–°–°–´–õ–ö–ê", '—Å—Å—ã–ª–∫–∞', text)
  text = rf"{text}"
  text = re.sub(r"\\n", " ", text)
  text = re.sub(r"\\t", " ", text)
  text = text.strip()
  amount_exclamations = 0
  for symbol in text:
    if symbol == "!":
      amount_exclamations += 1
  return text, neutral, positive, negative, amount_exclamations
```

–û–¥–Ω–∞ –∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –¥–∞–Ω–Ω—ã—Ö - –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è. –í –æ—Å–Ω–æ–≤–Ω–æ–º —è–∑—ã–∫ –∫–æ–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ - —Ä—É—Å—Å–∫–∏–π, –ø—Ä–∏ —ç—Ç–æ–º —è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∏—Ä—É—é—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–º. –õ–∞–∫–æ–Ω–∏—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ - –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —è–∑—ã–∫–æ–≤, —Ç–µ–º —Å–∞–º—ã–º –¥–µ—Ç–µ–∫—Ç–∏—Ä—É—è –Ω–∞–ª–∏—á–∏–µ –∫–æ–¥–∞:

 ‚Ä¢ –í–æ-–ø–µ—Ä–≤—ã—Ö –±—É–¥–µ–º –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ —è–∑—ã–∫–æ–≤ –≤ –∫–∞–∂–¥–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ \
 ‚Ä¢ –í–æ-–≤—Ç–æ—Ä—ã—Ö –∑–∞–º–µ—Ç–∏–º, —á—Ç–æ —Ä—É—Å—Å–∫–∏–π –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Å–ª–∞–≤—è–Ω—Å–∫–∏–º —è–∑—ã–∫–∞–º, —Ç–∞–∫ —á—Ç–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä –º–æ–∂–µ—Ç —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∏—Ö –≤–º–µ—Å—Ç–æ –Ω–µ–≥–æ \
 ‚Ä¢ –í-—Ç—Ä–µ—Ç—å–∏—Ö –ø–æ—Å—Ç–∞–≤–∏–º –ø–æ—Ä–æ–≥ –ø–æ –∏–Ω–æ—Å–ª–∞–≤—è–Ω—Å–∫–∏–º —è–∑—ã–∫–∞–º - 30% —Ç–µ–∫—Å—Ç–∞, –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–æ–¥–æ–º \
 ‚Ä¢ –í-—á–µ—Ç–≤–µ—Ä—Ç—ã—Ö –±—É–¥–µ–º —É–¥–∞–ª—è—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Å—Ç–æ–ø —Å–ª–æ–≤–∞ - "input", "print" –∏ —Ç.–¥.\
```{python}
def filter_code(text: str, filter_unknown_language=True) -> bool:
    code_stop_words = ["input", "print", "cin", "cout"]
    threshold = 30
    result_text = []
    have_code = False
    for line in text.strip().splitlines():
        foreign_languages_conf, sum_conf = 0, 0
        try:
            detection = Detector(line, quiet=True)
        except Exception as e:
            line = ''.join(x for x in line if x.isprintable())
            detection = Detector(line, quiet=True)
        for language in detection.languages:
            if language.code not in ["ru", "un", "be", "sr", "uk"]:
                foreign_languages_conf += language.confidence
            sum_conf += language.confidence
        if foreign_languages_conf > threshold:
            have_code = True
        else:
            if not filter_unknown_language or sum_conf:
                if all(stop_word not in line for stop_word in code_stop_words):
                    result_text.append(line)
    return "\n".join(result_text), have_code
```

–î–æ–±–∞–≤–∏–º –≤ –¥–∞—Ç–∞—Å–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–∑–∏—Ç–∏–≤–∞, –Ω–µ–≥–∞—Ç–∏–≤–∞, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –∞ —Ç–∞–∫–∂–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è:
```{python}
dataset[["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "Neutral", "Positive", "Negative", "Exclamations"]] = dataset.apply(lambda x: preprocessing_text(x["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]), axis=1, result_type="expand")
```


–î–æ–±–∞–≤–∏–º –≤ –¥–∞—Ç–∞—Å–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ —Ñ–∞–∫—Ç –Ω–∞–ª–∏—á–∏—è –∫–æ–¥–∞ –≤ —Ç–µ–∫—Å—Ç–µ:
```{python}
dataset[["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "have_code"]] = dataset.apply(lambda x: filter_code(x["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]), axis=1, result_type="expand")
```

–î–æ–±–∞–≤–∏–º –≤ –¥–∞—Ç–∞—Å–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–∑–∏—Ç–∏–≤–∞, –Ω–µ–≥–∞—Ç–∏–≤–∞, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –±–ª–∞–≥–æ–¥–∞—Ä—è NLP:
```{python}
dataset[["Neutral_NLP", "Positive_NLP", "Negative_NLP", "Speech_NLP"]] = [[el["neutral"], el["positive"], el["negative"], el["speech"]] for el in sentiment_model.predict(dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"], k=5)]
```

## Code Detection Analysis

### Example Library lingua

–ü–æ–ø—Ä–æ–±–æ–≤–∞–ª –±–∏–±–ª–∏–æ—Ç–µ–∫—É `lingua` –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ, –Ω–æ –æ–Ω–∞ —Ç–∞–∫ —Å–µ–±–µ –∑–∞—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞ –Ω–∞ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –ø—Ä–∏–º–µ—Ä–æ–≤:
```{python}
from lingua import Language, LanguageDetectorBuilder
languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH]
detector = LanguageDetectorBuilder.from_languages(*languages).build()
confidence_values = detector.compute_language_confidence_values("""–Ø –ø–æ–ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞–ª—Å—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ.
 surname=input('–í–≤–µ–¥–∏—Ç–µ —Ñ–∞–º–∏–ª–∏—é: ')
 name=input(""–í–≤–µ–¥–∏—Ç–µ –∏–º—è "")
 print('–í–∞—Å –∑–æ–≤—É—Ç - '+name,surname+'?')
 c=input 
 print('–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é –í–∞—Å, '+name,surname+'.', ' –Ø - –≤–∞—à –∫–æ–º–ø—å—é—Ç–µ—Ä.')""")
for confidence in confidence_values:
    print(f"{confidence.language.name}: {confidence.value:.2f}")
```

### Example Library polyglot
–ê –≤–æ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ `polyglot` –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –±–æ–ª–µ–µ 100 —è–∑—ã–∫–æ–≤, —É—Å—Ç–æ–π—á–∏–≤–∞ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö –∏ –æ—Ç–ª–∏—á–Ω–æ —Å–µ–±—è –∑–∞—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∞:

```{python}
#| code-fold: true
mixed_text = u"""–º–∏–Ω—É—Ç–∞ time = 6:23

–∏–º–µ–Ω–Ω–æ —Ç–∞–∫ —Å (func, args –∏ kwargs) ... –∞ –º–æ–∂–Ω–æ –∏ –Ω–µ —Ç–∞–∫ : 

 —Å—Å—ã–ª–∫–∞ 

 —Å—Å—ã–ª–∫–∞ 
+++++++++++++++++++++++++++++

from typing import Callable
# ================================================================================


def external_decorator :
 def decorator(func):
 def wrapper(*dec_args, **dec_kwargs):
 print('\n\t0_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–†\t""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"":\t', dec_args, dec_kwargs )
 return func(*dec_args, **dec_kwargs)
 return wrapper
 return decorator

# ================================================================================


 
def internal_decorator(*dargs, **dkwargs) -> Callable:
 print('\t1_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–†\t""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"":\t', dargs, dkwargs )
 def decorator(func):
 print('\t2_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–†\t""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"":\t', dargs, dkwargs)
 def wrapper(*args, **kwargs):
 print('\t3_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–†\t""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"":\t', dargs, dkwargs)
 print('\n–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–§–£–ù–ö–¶–ò–Æ\t""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"":\t', args, kwargs )
 return func(*args, **kwargs)
 return wrapper
 return decorator

# ================================================================================


 (100, '—Ä—É–±–ª–µ–π', 200, '–¥—Ä—É–∑–µ–π')
def function(text: str, num: int) -> None:
 print(""\n\t–ü—Ä–º–≤–µ—Ç"", text, num)

# ================================================================================


function(""–Æ–∑–µ—Ä"", 101)

... –ø–æ–≤—Ç–æ—Ä—é—Å—å (–∫–æ–º–º–µ–Ω—Ç –∫ –±–ª–æ–∫—É ‚Ññ16): –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã –æ–±—ä—è—Å–Ω—è—é—Ç—Å—è —Ñ–æ—Ä–º–∞–ª—å–Ω–æ (–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω–æ). –¥–∞–∂–µ –≤ –ø–æ—è—Å–Ω–µ–Ω–∏–∏ –∫ –ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–µ –¥–µ–∫–æ—Ä1[–¥–µ–∫–æ—Ä2[—Ñ—É–Ω–∫—Ü–∏—è(—Ñ—É–Ω–∫_–ø–∞—Ä–∞–º)], –¥–µ–∫1_–ø–∞—Ä–∞–º.] –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤—Å–∫–æ–ª—å–∑—å, –Ω–æ –Ω–µ –ø–æ—è—Å–Ω—è–µ—Ç—Å—è. 

++++++++++++++++++++++++++++++++

–≤ –æ–¥–Ω–æ–º –∏–∑ –º–æ–¥—É–ª–µ–π 16 –±—ã–ª–∞ –∑–∞–¥–∞—á–∞ —Å –¥–µ–∫–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ü–µ–ª–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞) ... –∞ –≤ —Ç–µ—Å—Ç–µ –±—ã–ª–∞ –∑–∞–¥–∞—á–∞ —Å –¥–µ–∫–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥—É–ª–µ–π –∫–ª–∞—Å—Å–æ–≤ –ø—Ä–∏ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –∫–ª–∞—Å—Å–æ–≤ B(A) ... —Ç–∞–∫ –≤–æ—Ç –ø—Ä–∏ —Ç–∞–∫–æ–º –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –¥–µ–∫–æ—Ä –≤—Å–µ–≥–æ –∫–ª–∞—Å—Å–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ... 
 —Å—Å—ã–ª–∫–∞ 
(—Å—Ç—Ä–æ–∫–∞ ‚Ññ52 - –µ—Å–ª–∏ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å )
---------------------------------------------------------------------------
TypeError Traceback (most recent call last)
<ipython-input-2-301b33d13241> in <cell line: 63> 
 63 (""%Y-%m-%d %H:%M:%S"")
 64 (timer)
---> 65 class B(A):
 66 def test_sum_1(self):
 67 print('xxxxxxxxxxxxxxxxx')
TypeError: function argument 'code' must be code, not str
+++++++++++++++++++++++++++++++++++++++++
 [–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä(–∫–ª–∞—Å—Å_B(–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä(–∫–ª–∞—Å—Å_–ê)))] - –∞ –∏–∑ –ª–µ–∫—Ü–∏–π —ç—Ç–æ(–ø–æ—á–µ–º—É –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç) –ø–æ–Ω—è—Ç—å —Å–ª–æ–∂–Ω–æ ... –∞ –≤ –ª–µ–∫—Ü–∏—è—Ö —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –Ω–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è ( 
—à–∞–≥ –≤–ª–µ–≤–æ. —à–∞–≥ –≤–ø—Ä–∞–≤–æ –∏ –≤—Å–µ ""—Å—ã–ø–∏—Ç—Å—è"" , –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è ""–≤–∞—à–∏–º–∏ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞–º–∏"" - —É—á–µ–±–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏.(((("""
mixed_text_preprocessing = u"""–º–∏–Ω—É—Ç–∞ time = 6:23

–∏–º–µ–Ω–Ω–æ —Ç–∞–∫ —Å (func, args –∏ kwargs) ... –∞ –º–æ–∂–Ω–æ –∏ –Ω–µ —Ç–∞–∫ : 

 —Å—Å—ã–ª–∫–∞ 

 —Å—Å—ã–ª–∫–∞ 
+++++++++++++++++++++++++++++

from typing import Callable
# ================================================================================


def external_decorator :
 def decorator(func):
 def wrapper(*dec_args, **dec_kwargs):
 print('  0_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–† ""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"": ', dec_args, dec_kwargs )
 return func(*dec_args, **dec_kwargs)
 return wrapper
 return decorator

# ================================================================================


 
def internal_decorator(*dargs, **dkwargs) -> Callable:
 print(' 1_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–† ""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"": ', dargs, dkwargs )
 def decorator(func):
 print(' 2_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–† ""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"": ', dargs, dkwargs)
 def wrapper(*args, **kwargs):
 print(' 3_–ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–î–ï–ö–û–†–ê–¢–û–† ""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"": ', dargs, dkwargs)
 print(' –ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –≤ _–§–£–ù–ö–¶–ò–Æ ""–∞—Ä–≥–∏"" –∏ ""–∫–≤–∞—Ä–≥–∏"": ', args, kwargs )
 return func(*args, **kwargs)
 return wrapper
 return decorator

# ================================================================================


 (100, '—Ä—É–±–ª–µ–π', 200, '–¥—Ä—É–∑–µ–π')
def function(text: str, num: int) -> None:
 print(""  –ü—Ä–º–≤–µ—Ç"", text, num)

# ================================================================================


function(""–Æ–∑–µ—Ä"", 101)

... –ø–æ–≤—Ç–æ—Ä—é—Å—å (–∫–æ–º–º–µ–Ω—Ç –∫ –±–ª–æ–∫—É ‚Ññ16): –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã –æ–±—ä—è—Å–Ω—è—é—Ç—Å—è —Ñ–æ—Ä–º–∞–ª—å–Ω–æ (–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω–æ). –¥–∞–∂–µ –≤ –ø–æ—è—Å–Ω–µ–Ω–∏–∏ –∫ –ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–µ –¥–µ–∫–æ—Ä1[–¥–µ–∫–æ—Ä2[—Ñ—É–Ω–∫—Ü–∏—è(—Ñ—É–Ω–∫_–ø–∞—Ä–∞–º)], –¥–µ–∫1_–ø–∞—Ä–∞–º.] –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤—Å–∫–æ–ª—å–∑—å, –Ω–æ –Ω–µ –ø–æ—è—Å–Ω—è–µ—Ç—Å—è. 

++++++++++++++++++++++++++++++++

–≤ –æ–¥–Ω–æ–º –∏–∑ –º–æ–¥—É–ª–µ–π 16 –±—ã–ª–∞ –∑–∞–¥–∞—á–∞ —Å –¥–µ–∫–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ü–µ–ª–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞) ... –∞ –≤ —Ç–µ—Å—Ç–µ –±—ã–ª–∞ –∑–∞–¥–∞—á–∞ —Å –¥–µ–∫–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ–º –º–æ–¥—É–ª–µ–π –∫–ª–∞—Å—Å–æ–≤ –ø—Ä–∏ –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –∫–ª–∞—Å—Å–æ–≤ B(A) ... —Ç–∞–∫ –≤–æ—Ç –ø—Ä–∏ —Ç–∞–∫–æ–º –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –¥–µ–∫–æ—Ä –≤—Å–µ–≥–æ –∫–ª–∞—Å—Å–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ... 
 —Å—Å—ã–ª–∫–∞ 
(—Å—Ç—Ä–æ–∫–∞ ‚Ññ52 - –µ—Å–ª–∏ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å )
---------------------------------------------------------------------------
TypeError Traceback (most recent call last)
<ipython-input-2-301b33d13241> in <cell line: 63> 
 63 (""%Y-%m-%d %H:%M:%S"")
 64 (timer)
---> 65 class B(A):
 66 def test_sum_1(self):
 67 print('xxxxxxxxxxxxxxxxx')
TypeError: function argument 'code' must be code, not str
+++++++++++++++++++++++++++++++++++++++++
 [–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä(–∫–ª–∞—Å—Å_B(–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä(–∫–ª–∞—Å—Å_–ê)))] - –∞ –∏–∑ –ª–µ–∫—Ü–∏–π —ç—Ç–æ(–ø–æ—á–µ–º—É –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç) –ø–æ–Ω—è—Ç—å —Å–ª–æ–∂–Ω–æ ... –∞ –≤ –ª–µ–∫—Ü–∏—è—Ö —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç –Ω–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è ( 
—à–∞–≥ –≤–ª–µ–≤–æ. —à–∞–≥ –≤–ø—Ä–∞–≤–æ –∏ –≤—Å–µ ""—Å—ã–ø–∏—Ç—Å—è"" , –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è ""–≤–∞—à–∏–º–∏ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞–º–∏"" - —É—á–µ–±–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏.(((("""
for language in Detector(mixed_text, quiet=True).languages:
  print(language)
```

–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞:
```{python}
#| echo: false

print(filter_code(mixed_text)[0])
```

–¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º:
```{python}
#| echo: false

print(filter_code(mixed_text_preprocessing)[0])
```

–ü—Ä–∏ —ç—Ç–æ–º –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–ª–Ω–æ—Å—Ç—å—é —É—Å—Ç–æ–π—á–∏–≤ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å –Ω–∞–ª–∏—á–∏–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö —Å–ª–æ–≤:
```{python}
print(filter_code("""–ó–¥—Ä–∞—Å—Ç–≤—É–π—Ç–µ. Hello World! 1. –î–æ —ç—Ç–æ–≥–æ —è –∏–∑—É—á–∞–ª–∞ —è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ Unix, Windows, –° –∏ Python, –Ω–µ–º–Ω–æ–≥–æ –≤–µ—Ä—Å—Ç–∫—É.
2. –°–µ–π—á–∞—Å –¥–µ–ª–∞—é —Ç–µ—Å—Ç–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è —Å—Ç–∞–∂–∏—Ä–æ–≤–∫–∏ –Ω–∞ php, —Ä–µ—à–∏–ª–∞ –Ω–µ–º–Ω–æ–≥–æ —É–∑–Ω–∞—Ç—å –ø—Ä–æ –æ—Å–Ω–æ–≤—ã.
3. –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –ø—Ä–∏—Å—ã–ª–∞—Ç—å –º–æ–∂–Ω–æ.""")[1])
```

–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∫–ª–∞—Å—Å–æ–≤—É—é —Ä–∞–∑–Ω–∏—Ü—É –ø–æ –Ω–∞–ª–∏—á–∏—é –∫–æ–¥–∞ –≤ —Ç–µ–∫—Å—Ç–∞—Ö:
```{python}
#| echo: false

dataset["have_code"].value_counts()
```

–£ –Ω–∞—Å –±–æ–ª—å—à–æ–π –¥–∏–∑–±–∞–ª–∞–Ω—Å –≤ –∫–ª–∞—Å—Å–∞—Ö, —Ç–∞–∫ —á—Ç–æ –ø–æ–¥–µ–ª–∏–º –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–º–ø–ª–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É:
```{python}
#| echo: false

groups_have_code = dataset.groupby("–ö–∞—Ç–µ–≥–æ—Ä–∏—è")["have_code"].sum()
data_have_code = {key: value / (dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == key).sum() for key, value in groups_have_code.to_dict().items() if key in categories}
ax = sns.barplot(x=data_have_code.keys(), y=data_have_code.values()) 
ax.set (ylabel='–ö–æ–ª-–≤–æ –∫–æ–¥–∞/–∫–æ–ª-–≤–æ —Å–µ–º–ø–ª–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
```

–•–æ—Ç—å —ç—Ç–æ –Ω–µ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω–æ, –Ω–æ –≤ –∫–ª–∞—Å—Å–µ `–î–ó` —Å—Ä–∞–≤–Ω–∏–º–æ –º–µ–Ω—å—à–µ –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–∞–ª–∏—á–∏—è –∫–æ–¥–∞ –≤ —Ç–µ–∫—Å—Ç–∞—Ö, –Ω–µ–∂–µ–ª–∏ —É –¥—Ä—É–≥–∏—Ö –∫–ª–∞—Å—Å–æ–≤. 

**–í—ã–≤–æ–¥—ã**: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏. –ü—Ä–∏–∑–Ω–∞–∫ `have_code` —Ç–æ–∂–µ —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, —Ç–∞–∫ –∫–∞–∫ —Ö–æ—Ä–æ—à–æ –≤—ã–¥–µ–ª—è–µ—Ç 3 –∫–ª–∞—Å—Ç–µ—Ä–∞ - (–í–∏–¥–µ–æ, –õ–æ–Ω–≥—Ä–∏–¥), (–î–ó), (–¢–µ—Å—Ç)

## Text sentiment analysis
–£ –Ω–∞—Å –µ—Å—Ç—å –¥–≤–∞ —Ç–∏–ø–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: \
‚Ä¢ –°–æ–±—Ä–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —ç–º–æ–¥–∑–∏ \
‚Ä¢ –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –±–ª–∞–≥–æ–¥–∞—Ä—è NLP-–º–æ–¥–µ–ª–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `dostoevsky` \

### NLP
–î–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–∏—Ö —Ñ–∏—á —É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ `boxplot`:

```{python}
#| echo: false
sns.boxplot(data=dataset, x="Neutral_NLP", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```
–ù–µ–ø–ª–æ—Ö–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –ø—Ä–æ—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏, –≤–∏–¥–Ω–æ –∏—Ö –∫–≤–∞—Ä—Ç–∏–ª–∏ —Å–∏–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è. –ê –Ω–∞–ª–∏—á–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ —Ç–∞–∫ —Å–æ–≤—Å–µ–º.

```{python}
#| echo: false

sns.boxplot(data=dataset, x="Positive_NLP", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```
–ó–¥–µ—Å—å —É–∂–µ –º–µ–Ω–µ–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∫–ª–∞—Å—Å—ã –ø–æ—Ö–æ–∂–∏, –æ–¥–Ω–∞–∫–æ —Å–∏—Ç—É–∞—Ü–∏—é –º–µ–Ω—è—é—Ç –≤—ã–±—Ä–æ—Å—ã –≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É `Positive` - —É –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 3—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –æ–Ω–∏ –æ–∫–æ–ª–æ –Ω—É–ª–µ–≤—ã–µ. –ü–æ–ª–∞–≥–∞—é —ç—Ç–∏ –∫–ª–∞—Å—Å—ã –Ω—É–∂–Ω—ã –¥–ª—è —Å–±–æ—Ä–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∏–¥–±–µ–∫–∞.  

```{python}
#| echo: false

sns.boxplot(data=dataset, x="Negative_NLP", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```

```{python}
#| echo: false

sns.barplot(data=dataset, x="Negative_NLP", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```
–ö–∞–∫ –∏ –ø–æ–ª–∞–≥–∞–ª–æ—Å—å, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –∫–ª–∞—Å—Å–∞ –±–æ–ª–µ–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ, –Ω–µ–∂–µ–ª–∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã.

```{python}
#| echo: false

sns.boxplot(data=dataset, x="Speech_NLP", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```

```{python}
#| echo: false

sns.barplot(data=dataset, x="Speech_NLP", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```
–ê –≤–æ—Ç –∑–¥–µ—Å—å –∫—Ä–∞–π–Ω–µ –Ω–µ–æ–±—ã—á–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ! –í–∏–¥–∏–º–æ –≤ –∫–ª–∞—Å—Å–µ `–î–ó` –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—Ç —Ç–µ–∫—Å—Ç–∞ —Å –Ω–∞–ª–∏—á–∏–µ–º –ø—Ä—è–º–æ–π –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ–π —Ä–µ—á–∏.

**–í—ã–≤–æ–¥—ã**: –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞–∂—É—Ç—Å—è –æ—á–µ–Ω—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º–∏ –¥–ª—è –º–æ–¥–µ–ª–∏, —Ç–æ—á–Ω–æ —Å–ª–µ–¥—É–µ—Ç –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è.

### Emoji
–î–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–∏—Ö —Ñ–∏—á —É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±—á–∞—Ç—É—é –¥–∏–∞–≥—Ä–∞–º–º—É:

```{python}
#| echo: false

sns.barplot(data=dataset, x="Neutral", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```

```{python}
#| echo: false

sns.barplot(data=dataset, x="Positive", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```

```{python}
#| echo: false

sns.barplot(data=dataset, x="Negative", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```

```{python}
#| echo: false

sns.barplot(data=dataset, x="Exclamations", y="–ö–∞—Ç–µ–≥–æ—Ä–∏—è")
```

**–í—ã–≤–æ–¥—ã**: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ NLP-—à–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —ç—Ç–∏ –∫–∞–∂—É—Ç—Å—è —Å–æ–≤—Å–µ–º –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–º–∏. –ù–æ –¥—É–º–∞—é, —á—Ç–æ –≤—Å—ë —Ä–∞–≤–Ω–æ —Å—Ç–æ–∏—Ç –ø—Ä–æ–≥–Ω–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –Ω–∞ –Ω–∏—Ö.

## –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è

–í –¥–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ –≤–∏–¥–µ–Ω —Å–º—ã—Å–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Downsampling –ø–æ –ø—Ä–∏—á–∏–Ω–µ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤, Upsampling –∑–¥–µ—Å—å –∫—É–¥–∞ –±–æ–ª–µ–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ–Ω. –ù–æ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –µ–≥–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞, –æ–¥–∏–Ω —Ñ–∞–∫—Ç —Å—Ç–∞–≤–∏—Ç —ç—Ç–æ –ø–æ–¥ —Å–æ–º–Ω–µ–Ω–∏–µ - 2 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑–º–µ—Ä—è—é—Ç—Å—è —Ç—ã—Å—è—á–∞–º–∏, –¥—Ä—É–≥–∏–µ 2 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–µ—Å—è—Ç–∫–∞–º–∏ —Ç—ã—Å—è—á. \\
–ì–æ–≤–æ—Ä—è –æ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, —Ç–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ —Ö–æ—Ç–∏–º –ø—Ä–∏–≤–µ—Å—Ç–∏ –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫ 23 000 —Å–µ–º–ø–ª–∞–º, –∫–∞–∫ —É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "–î–ó", –¥–ª—è —ç—Ç–æ–≥–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–ª–∏—Å—å –¥–≤–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: \
 ‚Ä¢ [–ü–∞—Ä–∞—Ñ—Ä–∞–∑–µ—Ä, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –Ω–∞ –±–∞–∑–µ ruT5](https://huggingface.co/cointegrated/rut5-base-paraphraser). –ü–æ–¥–æ–±–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–∑–∞–ª–æ—Å—å —Ö–æ—Ä–æ—à–∏–º, –æ–¥–Ω–∞–∫–æ –ø–æ –∏—Ç–æ–≥—É –±—ã–ª –≤–∏–¥–µ–Ω –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö (–±–æ–ª–µ–µ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π), –∞ —Ç–∞–∫–∂–µ –Ω–∏–∑–∫—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. \
 ‚Ä¢ ruGPT3-medium —Å —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–æ–º –Ω–∞ 4000 —Å–µ–º–ø–ª–∞—Ö. –í–∏–∑—É–∞–ª—å–Ω–æ –∫–∞–∂–µ—Ç—Å—è —Ö–æ—Ä–æ—à–∏–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –¥–ª –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–¥–Ω–∞–∫–æ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ—Å—è—Ç–∫–æ–≤ —Ç—ã—Å—è—á –Ω–∞ –æ–¥–Ω—É –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –≤—Å—ë —Ä–∞–≤–Ω–æ –ø—Ä–∏—Ö–æ–¥–∏–º –∫ –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤. –í —ç—Ç–æ–º —Ä–µ—à–µ–Ω–∏–∏ –≤–∏–∂—É –¥—Ä—É–≥—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É - —É—Ä–∞–≤–Ω—è—Ç—å –∫–ª–∞—Å—Å—ã "–î–ó" –∏ "–í–∏–¥–µ–æ", –∞ "–õ–æ–Ω–≥—Ä–∏–¥" —Å "–¢–µ—Å—Ç" –¥–æ 3-4 —Ç—ã—Å—è—á. –ê –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å FocalLoss –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∑–±–∞–ª–∞–Ω—Å–∞.

### ruGPT3-medium –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö

–î–ª—è –Ω–∞—á–∞–ª–∞ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –≤—ã—Å—Ç–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
```{python}
#| echo: false

lengths = [len(el) for el in dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]]
pd.Series(lengths).describe()
```

```{python}
#| echo: false

sns.displot(lengths, bins=100)
```

–¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º —Ç—É –∂–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∫–ª–∞—Å—Å–∞–º.
–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–î–ó":
```{python}
#| echo: false

sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–î–ó"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–í–∏–¥–µ–æ":
```{python}
#| echo: false

sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–í–∏–¥–µ–æ"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–¢–µ—Å—Ç":
```{python}
#| echo: false

sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–¢–µ—Å—Ç"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ö–∞—Ç–µ–≥–æ—Ä–∏—è "–õ–æ–Ω–≥—Ä–∏–¥":
```{python}
#| echo: false

sns.displot([len(el) for el in dataset[dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–õ–æ–Ω–≥—Ä–∏–¥"]["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]], bins=100)
```

–ò—Å—Ö–æ–¥—è –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, –º–æ–∂–Ω–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É 512 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –î–ª—è –æ–±—É—á–µ–Ω–∏—è ruGPT3 –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —Å–ø–µ—Ü. —Ç–æ–∫–µ–Ω–æ–≤:
```{python}
def convert(unit):
    category, text = unit["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"], unit["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]
    if category == "–î–ó":
        category = "–î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ"
    elif category == "–õ–æ–Ω–≥—Ä–∏–¥":
        category = "–û–±–∑–æ—Ä, –ª–æ–Ω–≥—Ä–∏–¥, long read"
    text = re.sub(r'\s+', ' ', text)
    text = f"<s>–¢–µ–º–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ Skillbox: {category}\n{text}</s>"
    return text
```
–ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ruGPT3:
```{python}
aug_data = dataset[(dataset["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].isin(['–í–∏–¥–µ–æ', '–î–ó', '–õ–æ–Ω–≥—Ä–∏–¥', '–¢–µ—Å—Ç'])) & (dataset["–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"].notna())]
train = aug_data.groupby('–ö–∞—Ç–µ–≥–æ—Ä–∏—è', group_keys=False).apply(lambda x: x.sample(1000))
train = train.sample(frac=1)
train_data = list(train[["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]].apply(convert, axis=1))
with open("train.txt", "w", encoding="utf-8") as file:
    file.write("\n".join(train_data))
```

–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è [—Ñ–∞–π–ª–æ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è gpt](https://raw.githubusercontent.com/buvanenko/finetune_rugpt3/main/pretrain_transformers.py), –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –°–±–µ—Ä–æ–º:
```{console}
python pretrain_transformers.py \
    --output_dir=essays_model \
    --model_type=gpt2 \
    --model_name_or_path=sberbank-ai/rugpt3medium_based_on_gpt2 \
    --do_train \
    --train_data_file=train.txt \
    --fp16 \
    --per_gpu_train_batch_size 1 \
    --gradient_accumulation_steps 1 \
    --num_train_epochs 5 \
    --block_size 2048 \
    --overwrite_output_dir
```

## –í—ã–≤–æ–¥—ã

1. –î–∞–Ω–Ω—ã–µ –æ—á–µ–Ω—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã, –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ—á–Ω–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞ —ç–º–±–µ–¥–∏–Ω–≥–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–ª–æ–≤. –°—Ç–æ–∏—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –∏–º–µ–Ω–∞, –æ–±—Ä–∞—â–µ–Ω–∏—è, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞. 
2. –£ –¥–∞–Ω–Ω—ã—Ö –æ–≥—Ä–æ–º–Ω—ã–π –¥–∏–∑–±–∞–ª–∞–Ω—Å –∏–∑-–∑–∞ –∫–æ—Ç–æ—Ä–æ–≥–æ downsampling –∏ upsampling —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø—Ä–∏–≤–µ–¥—É—Ç –∫ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É. –û–¥–Ω–∞–∫–æ —Å—Ä–∞–∑—É –æ—á–µ–≤–∏–¥–Ω–æ, —á—Ç–æ —Å—Ç–æ–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–∑–±–∞–ª–∞–Ω—Å–∞, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∏ FocalLoss.
3. –°—Ç–æ–∏—Ç —É–±—Ä–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '–ö–∞—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤', '–û–±—â–µ–Ω–∏–µ —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º', '–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã' –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.
4. –ò–∑ —ç–º–æ–¥–∑–∏ –∏ –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–π –≤–∑—è—Ç–∞ —Ö–æ—Ä–æ—à–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞. –≠—Ç–æ —É–∂–µ 4 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞, –≤–ø–æ–ª–Ω–µ –≤–æ–∑–º–æ–∂–Ω–æ –≤–∑—è—Ç—å –µ—â–µ –æ–¥–∏–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ bert deeppalov.